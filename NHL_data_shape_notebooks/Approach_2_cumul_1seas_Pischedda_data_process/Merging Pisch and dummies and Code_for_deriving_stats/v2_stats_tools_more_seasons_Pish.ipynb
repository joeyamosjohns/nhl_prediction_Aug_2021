{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c9f5d83-e74f-49ee-9bfa-b3ee630441f4",
   "metadata": {},
   "source": [
    "##I am splitting v3_Clean_model_add_Pis_feat.ipynb into 2 notebooks \n",
    "\n",
    "-another one on modelling v1_Model2_Pisch_Eval_Tuning.ipynb\n",
    "\n",
    "-this one on creating stats data set (just Pisch for now)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e3f7ba0-ee40-40c4-9a12-b43ec6ea2fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d466425-2aad-4edd-b1ed-08e10cb2eb2a",
   "metadata": {},
   "source": [
    "###some extra feature stuff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31964cc3-a094-479e-8a7b-ba475f666650",
   "metadata": {},
   "source": [
    "Some simple functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538b1203-369e-4595-b144-aa0de5e67954",
   "metadata": {},
   "outputs": [],
   "source": [
    "##have not written yet\n",
    "\n",
    "def top3_max_val_params(model, X, dates, drop_first=False):\n",
    "    pass\n",
    "    \n",
    "\n",
    "\n",
    "def perc_null(X):\n",
    "    \n",
    "    total = X.isnull().sum().sort_values(ascending=False)\n",
    "    data_types = X.dtypes\n",
    "    percent = (X.isnull().sum()/X.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "    missing_data = pd.concat([total, data_types, percent], axis=1, keys=['Total','Type' ,'Percent'])\n",
    "    return missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec81cb88-869d-4e7c-b786-b13d4dedb2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for  regressors predicting wins - losses, can use this to turn output into win prediction \n",
    "def fav_win(x):\n",
    "    if x <=0:\n",
    "        return 1\n",
    "    if x>0:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def make_win(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >0:\n",
    "        return 1\n",
    "\n",
    "v_make_win = np.vectorize(make_win)\n",
    "\n",
    "#useage: v_make_win(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb4f653f-2ede-4a43-a65a-082e51c82e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def one_plus(x):\n",
    "    return 1+x\n",
    "\n",
    "v_one_plus = np.vectorize(one_plus)\n",
    "\n",
    "def minus_one(x):\n",
    "    return x-1\n",
    "\n",
    "v_minus_one = np.vectorize(minus_one)\n",
    "\n",
    "def one_minus(x):\n",
    "    return 1-x\n",
    "\n",
    "v_one_minus = np.vectorize(one_minus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1253844-6231-4c15-b524-adce1bba8794",
   "metadata": {},
   "source": [
    "\n",
    "##Some more complex functions useful for generating new \n",
    "\n",
    "-basic stats (eg sh%)\n",
    "\n",
    "-cumulative stats for all prior games for that team up to the present date\n",
    "(not including present date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40fd6c76-0287-428f-9cee-7c7da800dd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##this function creates the dummy variables for you for evey team ...\n",
    "\n",
    "\n",
    "##HA_diff does dummies_home - dummies_away\n",
    "##HA_concat does dummies_home concat dummies_away (to the right)\n",
    "##! Concat veriosn shouls also do dummy for H/A since it is no linger encoded!\n",
    "## hmm ... maybe not.. HT_dummies, AT_dummies, HT_stats, AT_stats; Hg-Ag, HTWin \n",
    "\n",
    "def make_HA_diff(X, season, list_var_names = None ):\n",
    "    X = X.loc[X['season'] == season, :].copy()\n",
    "    X_H = X.loc[X['HoA'] == 'home',:].copy()\n",
    "    X_A = X.loc[X['HoA'] == 'away',:].copy()\n",
    "    X_H['goal_difference'] = X_H['goalsFor'] - X_H['goalsAgainst']  ##note every thing is based in home data\n",
    "    \n",
    "    #reset index to prep for df1.sub(df2)\n",
    "    X_H.reset_index(drop = True, inplace = True)\n",
    "    X_A.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    df_visitor = pd.get_dummies(X_H['nhl_name'], dtype=np.int64)\n",
    "    df_home = pd.get_dummies(X_A['nhl_name'], dtype=np.int64)\n",
    "    df_model = df_home.sub(df_visitor) \n",
    "    \n",
    "    for feat in ['won', 'goal_difference', 'Open']: ##will go in reverse order \n",
    "        df_model.insert(loc=0, column= feat, value=  X_H[feat].copy())\n",
    "   \n",
    "    #carefule with home and away teams \n",
    "    df_model.insert(loc=0, column= 'away_team', value=  X_A['nhl_name'].copy())\n",
    "    df_model.insert(loc=0, column= 'home_team', value=  X_H['nhl_name'].copy())\n",
    "    \n",
    "    df_model.insert(loc=0, column= 'full_date', value=  X_H['full_date'].copy())\n",
    "\n",
    "    df_model.insert(loc=0, column= 'game_id', value=  X_H['game_id'].copy())\n",
    "    \n",
    "    \n",
    "    #df_model['home_team'] = X_H['nhl_name'].copy()\n",
    "    #df_model['away_team'] = X_A['nhl_name'].copy() \n",
    "    \n",
    "    \n",
    "        #y = X_H.loc[:,['date', 'full_date','game_id', 'Open','goal_difference', 'won']].copy()   ##these are from home team perspective; 'Open' is for betting \n",
    "    return df_model\n",
    "\n",
    "##try later maye \n",
    "def make_HA_concat(X, season, list_var_names = None ):\n",
    "    X = X.loc[X['season'] == season, :].copy()\n",
    "    X_H = X.loc[X['HoA'] == 'home',:].copy()\n",
    "    X_A = X.loc[X['HoA'] == 'away',:].copy()\n",
    "    X_H['goal_difference'] = X_H['goalsFor'] - X_H['goalsAgainst']  ##note every thing is based in home data\n",
    "    X_H.reset_index(drop = True, inplace = True)\n",
    "    X_A.reset_index(drop = True, inplace = True)\n",
    "    df_visitor = pd.get_dummies(X_H['nhl_name'], dtype=np.int64)\n",
    "    df_home = pd.get_dummies(X_A['nhl_name'], dtype=np.int64)\n",
    "    #df_HA = pd.get_dummies(X['HoA']), dtype=np.int64)\n",
    "    \n",
    "    df_model = df_home.sub(df_visitor) \n",
    "    \n",
    "    \n",
    "    df_model['date'] = X_H['date']\n",
    "    df_model['full_date'] = X_H['full_date']\n",
    "    \n",
    "    df_model['game_id'] = X_H['game_id']\n",
    "    df_model['home_id'] = X_H['team_id']\n",
    "    df_model['away_id'] = X_A['team_id'] \n",
    "    y = X_H.loc[:,['date', 'full_date','game_id', 'Open','goal_difference', 'won']].copy()   ##these are from home team perspective; 'Open' is for betting \n",
    "    return (df_model, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10412ea7-b137-4c2d-bc6e-e16c1ce6330c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['won', 'goal_difference', 'Open', 'game_id', 'full_date', 'date']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['date', 'full_date','game_id', 'Open','goal_difference', 'won' ][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75701216-870a-48d8-be66-44627405043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_diff(statFor, statAway):\n",
    "    return statFor - statAway\n",
    "\n",
    "v_make_diff = np.vectorize(make_diff)\n",
    "\n",
    "def make_per(statFor, statAway):  #example FOWFor/(FOWFor + FOWAgainst)  or ShAt\n",
    "    try: \n",
    "        return statFor/(statFor+statAway)\n",
    "    except: \n",
    "        return 0\n",
    "\n",
    "\n",
    "v_make_per = np.vectorize(make_per)\n",
    " \n",
    "    \n",
    "def make_ratio(stat1, stat2):  #example goalsFor/shotsFor = sh%\n",
    "    try:\n",
    "        return stat1/stat2\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "v_make_ratio = np.vectorize(make_ratio)\n",
    "\n",
    "##have to adjust later depending what is convenient to use for stat name ... \n",
    "\n",
    "#not using k_days_back .. will use a unioversal fn to just avg past games...\n",
    "#makes more sense ,,, if they get a 1000 shots against one game, don't want that to leak into \n",
    "#other games .. \n",
    "\n",
    "\n",
    "\n",
    "def get_per(X, statFor): \n",
    "    #stat_name = goalsFor or faceoffsWonFor  example to keep in mind ... mp style\n",
    "    ##we do this so we can loop thru existing names in our feature list\n",
    "    stat_name = statFor[:-3]  #remove last 3\n",
    "    #statFor = stat_name+'For'\n",
    "    statAgainst = stat_name+'Against'\n",
    "    X[statFor+'%' ] = v_make_per(X.loc[:,statFor],X.loc[:,statAgainst]) \n",
    "    #return v_make_per(X.loc[:,statFor],X.loc[:,statAgainst])\n",
    "\n",
    "\n",
    "def get_ratio(X, stat1, stat2, new_stat_name):  #stat1/stat2  \n",
    "    #stat_name = goalsFor or faceoffsWonFor  example to keep in mind ... mp style\n",
    "    ##we do this so we can loop thru existing names in our feature list\n",
    "    \n",
    "    X[new_stat_name] = v_make_ratio(X.loc[:,stat1],X.loc[:,stat2]) \n",
    "    #return v_make_ratio(X.loc[:,stat1],X.loc[:,stat2])\n",
    "\n",
    "def get_diff(X, statFor): \n",
    "    #stat_name = goalsFor or faceoffsWonFor  example to keep in mind ... mp style\n",
    "    ##we do this so we can loop thru existing names in our feature list\n",
    "    stat_name = statFor[:-3]  #remove last 3\n",
    "    #statFor = stat_name+'For'\n",
    "    statAgainst = stat_name+'Against'\n",
    "    X[stat_name+'Diff']= v_make_diff(X.loc[:,statFor],X.loc[:, statAgainst])\n",
    "    #return v_make_diff(X.loc[:,statFor],X.loc[:, statAgainst])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34bf2a22-e406-4b12-a184-2db707428529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 8]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted({8,5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e07304d-525a-42e7-be6d-314e31c1f154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 434, 45, 5, 566, 6]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2,3,434,45,5,566,6,][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdad13f7-ab8c-4936-b1ef-f30ebf4f9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "##!! you need to loop over nhl_name at the beginning so your dates are associated to that fixed team\n",
    "\n",
    "\n",
    "#stat_name goalsFor for example\n",
    "def get_k_game_sum(X, stat_name, k_days_back= 10**6 ): #k_days_back #season is random-default \n",
    "   \n",
    "    #make string version of k_days_back for later; 10**6 means go back forever to beginning of season\n",
    "    if k_days_back < 10**6:\n",
    "        str_k = '_'+str(k_days_back)+'_day'\n",
    "    else: \n",
    "        str_k = \"_cumul\"\n",
    "    \n",
    "    #set up column eg goalFor_10_days or \n",
    "    X[stat_name+str_k+'_sum'] = np.NaN  \n",
    "    \n",
    "     #doing set removes duplicates; sorted makes increasing ordered list \n",
    "    all_teams = list(set(X['nhl_name']))   \n",
    "    \n",
    "    for nhl_name0 in all_teams:  #I'll label in nahl_name0 to emphasize it is fixed constant\n",
    "        \n",
    "        ## this is all the dates *that have this tean nhl_name playing*\n",
    "        team0_dates  = sorted(set(X.loc[X['nhl_name'] == nhl_name0, 'full_date'])) \n",
    "        \n",
    "        \n",
    "        #note: first date0 of teh season for the team is special because date < date0 will be empty\n",
    "        \n",
    "        for date1 in team0_dates[1:]: #all but first date so don't get empty object with date< date1\n",
    "            team0_dates_bef_date1 = [date for date in team0_dates if date < date1]  #for the fixed team\n",
    "            team0_k_dates_bef_date1 = team0_dates_bef_date1[-k_days_back :] # this further restricts to the last k days of list; \n",
    "                                                                # or returns all for large k_days_back, [1,2][-10,:] = [1,2]\n",
    "                                                                #will be nonempty if k_days_back >0\n",
    "            #we have to restrict to k *team = nhl_name0* games so that's why we do it here \n",
    "                    \n",
    "            #restrict the df to just team0 and dates  < date1 (this is where we get empty if date1 =date0 )\n",
    "            X_team0_k_bef_date1 = X.loc[(X['nhl_name'] == nhl_name0) & X['full_date'].isin(team0_k_dates_bef_date1), :].copy()           \n",
    "           \n",
    "            #main step; first calculate the sum for nhl_name0 and dates < date1 \n",
    "            k_sum = np.sum(X_team0_k_bef_date1[stat_name])\n",
    "            \n",
    "            #here we assign the value to a unique row of the original X which was passed\n",
    "            #the new columns is eg goalsFor_10_sum or goals_for_cumul_sum\n",
    "            \n",
    "            X.loc[(X['full_date'] == date1)& (X['nhl_name'] == nhl_name0) , stat_name+str_k+'_sum'] =k_sum\n",
    "    \n",
    "    #you can either operate directly on X which was passed, adding a new column, or you could return a df ... \n",
    "    #so far seems convenient to do the former\n",
    "    #return X\n",
    "\n",
    "            \n",
    "            \n",
    "            #huh? this below is wrong ... date1 should not be touched\n",
    "            #k_sum = X.loc[(X['full_date'] == date1)& (X['nhl_name'] == nhl_name) , stat_name] ##should be single number anyway\n",
    "            #X.loc[(X['full_date'] == date1)& (X['nhl_name'] == nhl_name) , stat_name+str_k+'_sum'] =k_sum\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5381419-1fce-40ea-8099-b965b1bb822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##!! you need to loop over nhl_name at the beginning so your dates are associated to that fixed team\n",
    "\n",
    "\n",
    "#stat_name goalsFor for example\n",
    "def get_k_game_avg(X, stat_name, k_days_back= 10**6 ): #k_days_back #season is random-default \n",
    "   \n",
    "    #make string version of k_days_back for later; 10**6 means go back forever to beginning of season\n",
    "    if k_days_back < 10**6:\n",
    "        str_k = '_'+str(k_days_back)+'_day'\n",
    "    else: \n",
    "        str_k = \"_cumul\"\n",
    "    \n",
    "    #set up column eg goalFor_10_days or \n",
    "    X[stat_name+str_k+'_avg'] = np.NaN  \n",
    "    \n",
    "     #doing set removes duplicates; sorted makes increasing ordered list \n",
    "    all_teams = list(set(X['nhl_name']))   \n",
    "    \n",
    "    for nhl_name0 in all_teams:  #I'll label in nahl_name0 to emphasize it is fixed constant\n",
    "        \n",
    "        ## this is all the dates *that have this tean nhl_name playing*\n",
    "        team0_dates  = sorted(set(X.loc[X['nhl_name'] == nhl_name0, 'full_date'])) \n",
    "        \n",
    "        \n",
    "        #note: first date0 of teh season for the team is special because date < date0 will be empty\n",
    "        \n",
    "        for date1 in team0_dates[1:]: #all but first date so don't get empty object with date< date1\n",
    "            team0_dates_bef_date1 = [date for date in team0_dates if date < date1]  #for the fixed team\n",
    "            team0_k_dates_bef_date1 = team0_dates_bef_date1[-k_days_back :] # this further restricts to the last k days of list; \n",
    "                                                                # or returns all for large k_days_back, [1,2][-10,:] = [1,2]\n",
    "                                                                #will be nonempty if k_days_back >0\n",
    "            #we have to restrict to k *team = nhl_name0* games so that's why we do it here \n",
    "                    \n",
    "            #restrict the df to just team0 and dates  < date1 (this is where we get empty if date1 =date0 )\n",
    "            X_team0_k_bef_date1 = X.loc[(X['nhl_name'] == nhl_name0) & X['full_date'].isin(team0_k_dates_bef_date1), :].copy()           \n",
    "           \n",
    "            #main step; first calculate the sum for nhl_name0 and dates < date1 \n",
    "            k_avg = np.mean(X_team0_k_bef_date1[stat_name])\n",
    "            \n",
    "            #here we assign the value to a unique row of the original X which was passed\n",
    "            #the new columns is eg goalsFor_10_avg or goals_for_cumul_avg\n",
    "            \n",
    "            X.loc[(X['full_date'] == date1)& (X['nhl_name'] == nhl_name0) , stat_name+str_k+'_avg'] =k_avg\n",
    "    \n",
    "    #you can either operate directly on X which was passed, adding a new column, or you could return a df ... \n",
    "    #so far seems convenient to do the former\n",
    "    #return X\n",
    "\n",
    "            \n",
    "            \n",
    "            #huh? this below is wrong ... date1 should not be touched\n",
    "            #k_sum = X.loc[(X['full_date'] == date1)& (X['nhl_name'] == nhl_name) , stat_name] ##should be single number anyway\n",
    "            #X.loc[(X['full_date'] == date1)& (X['nhl_name'] == nhl_name) , stat_name+str_k+'_sum'] =k_sum\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd46457-7c5e-4873-a5da-79b0d0adf86e",
   "metadata": {},
   "source": [
    "##Now let's run thru generating the Pisch data set again ... (some corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38666e7c-c201-4f0a-b98f-bdc833da6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"/Users/joejohns/data_bootcamp/GitHub/final_project_nhl_prediction/Data/Shaped_Data/data_bet_stats_mp.csv\")\n",
    "data.drop(columns=[ 'Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4140b24c-281f-4d2c-a055-58d9d9c64d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['won'] = data['won'].apply(int)\n",
    "data_playoffs = data.loc[data['playoffGame'] == 1, :].copy()  #set aside playoff games ... probably won't use them.\n",
    "data=  data.loc[data['playoffGame'] == 0, :].copy() \n",
    "#fix the Nans in FOW%:\n",
    "data['faceOffTotalBothTeams'] = data['faceOffsWonFor'] + data['faceOffsWonAgainst']\n",
    "data['faceOffWinPercentage'] = v_make_ratio(data['faceOffsWonFor'],data['faceOffTotalBothTeams'])\n",
    " \n",
    "#sorted(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b11d2bb2-2723-4fa9-907c-017be1e90cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad_game_ids with 0 0 score (in df_game_team_stats) ,df_game is probably ok \n",
    "bad_game_ids = [2008020057, 2008020071, 2008020306, 2008020623, 2008021108,\n",
    "            2008021196, 2009020072, 2009020253, 2009020682, 2009020831,\n",
    "            2009021118, 2009021209, 2010020382, 2010020761, 2010020878,\n",
    "            2010021111, 2011020749, 2011020787, 2011021016, 2011021052,\n",
    "            2011021108, 2012020159, 2012020412, 2012020487, 2013020126,\n",
    "            2013021136, 2013021223, 2014020055, 2014020158, 2014020313,\n",
    "            2014020456, 2014021008, 2014021210, 2016020785, 2017020561,\n",
    "            2017020965, 2018020783, 2019020127, 2019021041]\n",
    "\n",
    "##impute the missing 00 games\n",
    "data.loc[data['game_id'].isin(bad_game_ids)&(data['won']==1),'goalsFor'] = 1.0\n",
    "data.loc[data['game_id'].isin(bad_game_ids)&(data['won']==0), 'goalsAgainst'] = 1.0\n",
    "\n",
    "#verify\n",
    "#data.loc[data['game_id'].isin(bad_game_ids), ['won', 'goalsFor', 'goalsAgainst']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bac0530-ad51-47b4-a62e-dab1f746ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "###debugging ... why am I gettin 47% nan in dummies and date, id float?\n",
    "\n",
    "\n",
    "perc_null(data.loc[data['season'] ==season, :])\n",
    "\n",
    "season = 20152016\n",
    "\n",
    "X_seas = data.loc[data['season'] ==season, :].copy()\n",
    "\n",
    "#Here Pis is for Pischada ... I am following a 2013 paper which he based on the Weissenbock paper (he is at U Ottawa)\n",
    "#Piscada paper file:///Users/joejohns/Downloads/PredictingNHLmatchoutcomeswithMLmodels%20(1).pdf\n",
    "\n",
    "feat_Pis = ['goalsAgainst', 'goalsFor', 'goalDiff', 'goal_perc', 'PP%', 'PK%', 'sh%', 'sv%', \n",
    "            'win_streak_grouped_10', 'conference_standing_grouped_10','Fclose%', 'PDO'] \n",
    "\n",
    "##these ae teh features from X_seas I will need to build the Pisch features\n",
    "\n",
    "feat_for_Pis_small = [ 'goalsAgainst','goalsFor', 'powerPlayGoals','powerPlayOpportunities',  'shotsOnGoalAgainst',\n",
    "                      'shotsOnGoalFor','savedShotsOnGoalAgainst','savedShotsOnGoalFor', 'fenwickPercentage',] \n",
    "\n",
    "#we start with pp% and pk% below\n",
    "\n",
    "    get_ratio(X_seas,  'powerPlayGoals','powerPlayOpportunities', 'pp%')\n",
    "\n",
    "#to do pk% (no SHgoalsAgainst) so we use pk% of HT = 1- pp% of AT and vice versa\n",
    "\n",
    "#set up the pk% column initialized with 0\n",
    "\n",
    "    X_seas['pk%'] = 0\n",
    "\n",
    "##to make this 1-pk% work we make sure the indices are set up consistently (not sure if needed)\n",
    "\n",
    "    X_seas.sort_values(by = ['full_date', 'game_id', 'HoA'], inplace = True)\n",
    "    X_seas.reset_index(drop = True, inplace = True)\n",
    "\n",
    "##note: The following 2 lines did not work when I had X_seas = (...) with no .copy() above!\n",
    "    X_seas.loc[X_seas['HoA'] == 'home', 'pk%']  = v_one_minus(X_seas.loc[X_seas['HoA'] == 'away' ,['pp%']].copy())\n",
    "    X_seas.loc[X_seas['HoA'] == 'away', 'pk%'] =  v_one_minus(X_seas.loc[X_seas['HoA'] == 'home' ,['pp%']].copy())\n",
    "\n",
    "\n",
    "#this creates gfdiff, gf%, sh%, sv%\n",
    "    get_diff(X_seas, 'goalsFor')\n",
    "    get_per(X_seas, 'goalsFor')\n",
    "    get_ratio(X_seas, 'goalsFor', 'shotsOnGoalFor', 'sh%')\n",
    "    get_ratio(X_seas, 'savedShotsOnGoalAgainst', 'shotsOnGoalAgainst', 'sv%')\n",
    "#X_seas['sv%'] = one_minus(X_seas['sv%']) don't need this now ... used savedSHA\n",
    "\n",
    "#pdo is simple sum\n",
    "    X_seas['PDO'] = X_seas['sh%'] + X_seas['sv%']\n",
    "\n",
    "##we create a column of 1s to calculated games so far\n",
    "    X_seas['ones'] = 1\n",
    "    get_k_game_sum(X_seas, 'ones')\n",
    "    get_k_game_sum(X_seas, 'won') \n",
    "\n",
    "    X_seas.rename(columns = {'ones_cumul_sum': 'team_games_so_far'}, inplace = True)  #counts num of games so far for that team\n",
    "##total wins and win% (I am ignoring distinction OT/SO/Reg)\n",
    "\n",
    "    get_ratio(X_seas, 'won_cumul_sum', 'team_games_so_far', 'win%_cumul')\n",
    "\n",
    "##total wins and win% in the last 10 games ... later can try different versions\n",
    "    get_k_game_sum(X_seas, 'won', k_days_back=10)\n",
    "    get_k_game_sum(X_seas, 'ones', k_days_back=10)\n",
    "    get_ratio(X_seas, 'won_10_day_sum','ones_10_day_sum','win%_last_10_games')\n",
    "\n",
    "\n",
    "    feat_Pis_to_sum  = ['goalsAgainst', 'goalsFor', 'goalsDiff']\n",
    "    feat_Pis_to_avg = ['goalsFor%',  'pp%', 'pk%',  'sh%', 'sv%', 'PDO','fenwickPercentage', \n",
    "'corsiPercentage',  'xGoalsPercentage',   ]  ##added corsi and xgoals \n",
    "\n",
    "##NOTE! This is a bit inaccurate to average these ... one should find cumul_sums then do the % calculations above for accurate %\n",
    "##let's see if they are that different ... \n",
    "\n",
    "#'last_10_games_win%',  'win%',     omtted because already a 10 gm avg, \n",
    "\n",
    "    for feat_to_sum in feat_Pis_to_sum:\n",
    "        get_k_game_sum(X_seas, feat_to_sum)\n",
    "    \n",
    "    \n",
    "\n",
    "    for feat_to_avg in feat_Pis_to_avg:\n",
    "        get_k_game_avg(X_seas, feat_to_avg)\n",
    "        \n",
    "    ##get dummies \n",
    "\n",
    "\n",
    "    feat_Pis = ['goalsAgainst', 'goalsFor', 'goal_diff', 'goal_perc', 'PP%', 'PK%', 'sh%', 'sv%', \n",
    "            'win_streak_grouped_10', 'conference_standing_grouped_10','Fclose%', 'PDO'] \n",
    "#did win% and win%_last_10 instead of streak and standing ... did regular fenwick, not fenclose\n",
    "#might be good to group these into 5-10 groups ... \n",
    "\n",
    "\n",
    "\n",
    "    data_Pis_pre_xg_corsi = X_seas.loc[:, ['HoA',\n",
    "       'goalsAgainst_cumul_sum', 'goalsFor_cumul_sum', \n",
    "        'goalsDiff_cumul_sum', 'goalsFor%_cumul_avg',\n",
    "       'pp%_cumul_avg', 'pk%_cumul_avg', \n",
    "        'sh%_cumul_avg', 'sv%_cumul_avg',\n",
    "        'PDO_cumul_avg', 'fenwickPercentage_cumul_avg', 'corsiPercentage_cumul_avg',  'xGoalsPercentage_cumul_avg',\n",
    "        'win%_last_10_games',   'win%_cumul', ]].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a33ea945-82f9-4f6d-a918-1dc460b5daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dic ={}\n",
    "#set season = 20122013  #select this shortened season because same as Pisch\n",
    "\n",
    "for season in [20152016, 20162017, 20172018, 20182019]:\n",
    "\n",
    "    X_seas = data.loc[data['season'] ==season, :].copy()\n",
    "\n",
    "#Here Pis is for Pischada ... I am following a 2013 paper which he based on the Weissenbock paper (he is at U Ottawa)\n",
    "#Piscada paper file:///Users/joejohns/Downloads/PredictingNHLmatchoutcomeswithMLmodels%20(1).pdf\n",
    "\n",
    "    feat_Pis = ['goalsAgainst', 'goalsFor', 'goalDiff', 'goal_perc', 'PP%', 'PK%', 'sh%', 'sv%', \n",
    "            'win_streak_grouped_10', 'conference_standing_grouped_10','Fclose%', 'PDO'] \n",
    "\n",
    "##these ae teh features from X_seas I will need to build the Pisch features\n",
    "\n",
    "    feat_for_Pis_small = [ 'goalsAgainst','goalsFor', 'powerPlayGoals','powerPlayOpportunities',  'shotsOnGoalAgainst',\n",
    "                      'shotsOnGoalFor','savedShotsOnGoalAgainst','savedShotsOnGoalFor', 'fenwickPercentage',] \n",
    "\n",
    "#we start with pp% and pk% below\n",
    "\n",
    "    get_ratio(X_seas,  'powerPlayGoals','powerPlayOpportunities', 'pp%')\n",
    "\n",
    "#to do pk% (no SHgoalsAgainst) so we use pk% of HT = 1- pp% of AT and vice versa\n",
    "\n",
    "#set up the pk% column initialized with 0\n",
    "\n",
    "    X_seas['pk%'] = 0\n",
    "\n",
    "##to make this 1-pk% work we make sure the indices are set up consistently (not sure if needed)\n",
    "\n",
    "    X_seas.sort_values(by = ['full_date', 'game_id', 'HoA'], inplace = True)\n",
    "    X_seas.reset_index(drop = True, inplace = True)\n",
    "\n",
    "##note: The following 2 lines did not work when I had X_seas = (...) with no .copy() above!\n",
    "    X_seas.loc[X_seas['HoA'] == 'home', 'pk%']  = v_one_minus(X_seas.loc[X_seas['HoA'] == 'away' ,['pp%']].copy())\n",
    "    X_seas.loc[X_seas['HoA'] == 'away', 'pk%'] =  v_one_minus(X_seas.loc[X_seas['HoA'] == 'home' ,['pp%']].copy())\n",
    "\n",
    "\n",
    "#this creates gfdiff, gf%, sh%, sv%\n",
    "    get_diff(X_seas, 'goalsFor')\n",
    "    get_per(X_seas, 'goalsFor')\n",
    "    get_ratio(X_seas, 'goalsFor', 'shotsOnGoalFor', 'sh%')\n",
    "    get_ratio(X_seas, 'savedShotsOnGoalAgainst', 'shotsOnGoalAgainst', 'sv%')\n",
    "#X_seas['sv%'] = one_minus(X_seas['sv%']) don't need this now ... used savedSHA\n",
    "\n",
    "#pdo is simple sum\n",
    "    X_seas['PDO'] = X_seas['sh%'] + X_seas['sv%']\n",
    "\n",
    "##we create a column of 1s to calculated games so far\n",
    "    X_seas['ones'] = 1\n",
    "    get_k_game_sum(X_seas, 'ones')\n",
    "    get_k_game_sum(X_seas, 'won') \n",
    "\n",
    "    X_seas.rename(columns = {'ones_cumul_sum': 'team_games_so_far'}, inplace = True)  #counts num of games so far for that team\n",
    "##total wins and win% (I am ignoring distinction OT/SO/Reg)\n",
    "\n",
    "    get_ratio(X_seas, 'won_cumul_sum', 'team_games_so_far', 'win%_cumul')\n",
    "\n",
    "##total wins and win% in the last 10 games ... later can try different versions\n",
    "    get_k_game_sum(X_seas, 'won', k_days_back=10)\n",
    "    get_k_game_sum(X_seas, 'ones', k_days_back=10)\n",
    "    get_ratio(X_seas, 'won_10_day_sum','ones_10_day_sum','win%_last_10_games')\n",
    "\n",
    "\n",
    "    feat_Pis_to_sum  = ['goalsAgainst', 'goalsFor', 'goalsDiff']\n",
    "    feat_Pis_to_avg = ['goalsFor%',  'pp%', 'pk%',  'sh%', 'sv%', 'PDO','fenwickPercentage', \n",
    "'corsiPercentage',  'xGoalsPercentage',   ]  ##added corsi and xgoals \n",
    "\n",
    "##NOTE! This is a bit inaccurate to average these ... one should find cumul_sums then do the % calculations above for accurate %\n",
    "##let's see if they are that different ... \n",
    "\n",
    "#'last_10_games_win%',  'win%',     omtted because already a 10 gm avg, \n",
    "\n",
    "    for feat_to_sum in feat_Pis_to_sum:\n",
    "        get_k_game_sum(X_seas, feat_to_sum)\n",
    "    \n",
    "    \n",
    "\n",
    "    for feat_to_avg in feat_Pis_to_avg:\n",
    "        get_k_game_avg(X_seas, feat_to_avg)\n",
    "        \n",
    "    ##get dummies \n",
    "\n",
    "\n",
    "    feat_Pis = ['goalsAgainst', 'goalsFor', 'goal_diff', 'goal_perc', 'PP%', 'PK%', 'sh%', 'sv%', \n",
    "            'win_streak_grouped_10', 'conference_standing_grouped_10','Fclose%', 'PDO'] \n",
    "#did win% and win%_last_10 instead of streak and standing ... did regular fenwick, not fenclose\n",
    "#might be good to group these into 5-10 groups ... \n",
    "\n",
    "\n",
    "\n",
    "    data_Pis_pre_xg_corsi = X_seas.loc[:, ['HoA',\n",
    "       'goalsAgainst_cumul_sum', 'goalsFor_cumul_sum', \n",
    "        'goalsDiff_cumul_sum', 'goalsFor%_cumul_avg',\n",
    "       'pp%_cumul_avg', 'pk%_cumul_avg', \n",
    "        'sh%_cumul_avg', 'sv%_cumul_avg',\n",
    "        'PDO_cumul_avg', 'fenwickPercentage_cumul_avg', 'corsiPercentage_cumul_avg',  'xGoalsPercentage_cumul_avg',\n",
    "        'win%_last_10_games',   'win%_cumul', ]].copy()\n",
    "    \n",
    "\n",
    "    data_Pis_pre = X_seas.loc[:, ['HoA',\n",
    "       'goalsAgainst_cumul_sum', 'goalsFor_cumul_sum', \n",
    "        'goalsDiff_cumul_sum', 'goalsFor%_cumul_avg',\n",
    "       'pp%_cumul_avg', 'pk%_cumul_avg', \n",
    "        'sh%_cumul_avg', 'sv%_cumul_avg',\n",
    "        'PDO_cumul_avg', 'fenwickPercentage_cumul_avg', \n",
    "        'win%_last_10_games',   'win%_cumul', ]].copy()\n",
    "\n",
    "    \n",
    "    #df_dic[\"data_Pis_pre_xg_corsi_\"+str(season)] = data_Pis_pre_xg_corsi\n",
    "    #df_dic[\"data_Pis_pre_\"+str(season)] = data_Pis_pre\n",
    "#targets   \n",
    "#  'won', 'goal_difference' ,'goalsAgainst','goalsFor', 'Open'\n",
    "#id stuff\n",
    "##'full_date','season', 'game_id', 'nhl_name','HoA','opposingTeam', \n",
    "\n",
    "    data_Pis_H = data_Pis_pre.loc[data_Pis_pre['HoA'] =='home',:].copy()\n",
    "    data_Pis_A = data_Pis_pre.loc[data_Pis_pre['HoA'] =='away',:].copy()\n",
    "\n",
    "#reset index for df1.sub(df2)\n",
    "    data_Pis_A.reset_index(drop = True, inplace = True)\n",
    "    data_Pis_H.reset_index(drop = True, inplace = True)\n",
    "\n",
    "##set the numerical data to home stats - away stats \n",
    "    data_Pis = data_Pis_H.iloc[:, 1:].copy().sub(data_Pis_A.iloc[:, 1:].copy()).copy()   #remove the 'HoA' column with 1:\n",
    "\n",
    "\n",
    "    dummies_pm1_Pis = make_HA_diff(data, season = season).copy()  #single df, has id stuff and target stuff!\n",
    "    dummies_pm1_Pis.reset_index(drop = True, inplace =True)\n",
    "\n",
    "#combine dummies and data \n",
    "    data_dummies_Pis = pd.concat([dummies_pm1_Pis, data_Pis], axis =1)\n",
    "    \n",
    "    df_dic[\"data_Pis_pre_xg_corsi_\"+str(season)] = data_dummies_Pis\n",
    "    \n",
    "    filename_seas = 'data_dummies_Pis_xg_Corsi_v3_'+str(season)+'.csv'\n",
    "    data_dummies_Pis.to_csv(filename_seas)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d2cf67-d02e-4063-8003-45763e226a2b",
   "metadata": {},
   "source": [
    "##moved into for loop over seasons ...\n",
    "\n",
    "feat_Pis_to_sum  = ['goalsAgainst', 'goalsFor', 'goalsDiff']\n",
    "feat_Pis_to_avg = ['goalsFor%',  'pp%', 'pk%',  'sh%', 'sv%', 'fenwickPercentage', 'PDO',    ]  \n",
    "\n",
    "##NOTE! This is a bit inaccurate to average these ... one should find cumul_sums then do the % calculations above for accurate %\n",
    "##let's see if they are that different ... \n",
    "\n",
    "#'last_10_games_win%',  'win%',     omtted because already a 10 gm avg, \n",
    "\n",
    "for feat_to_sum in feat_Pis_to_sum:\n",
    "    get_k_game_sum(X_12, feat_to_sum)\n",
    "    \n",
    "    \n",
    "\n",
    "for feat_to_avg in feat_Pis_to_avg:\n",
    "    get_k_game_avg(X_12, feat_to_avg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b7bc24-2b77-4a26-8395-a89f8c258545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check stuff 'SJS', 'ANA' ... looks good\n",
    "\n",
    "##chnage X_12 to X_20162017 = pd.read_csv(...)\n",
    "#X_12.loc[X_12['nhl_name'] == 'SJS', ['won','nhl_name', 'team_games_so_far','full_date', 'sv%', 'sv%_cumul_avg', 'win%',  'won_10_day_sum','ones_10_day_sum','last_10_games_win%']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a45880-e6dc-42d8-b08f-d69e5295f46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a652185-d2a7-4918-a5d2-6e215058a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "##note: restrict the dates later if you want to muchacho\n",
    "##and remove the target etc at modelling time\n",
    "#data_dummies_Pis.iloc[20:50,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8811940-fbd3-4479-90e6-4f7e31a13987",
   "metadata": {},
   "outputs": [],
   "source": [
    "##fiddle with this later\n",
    "\n",
    "\n",
    "feat_mine = [ 'full_date',\n",
    "'season',\n",
    " 'game_id',\n",
    "'HoA',\n",
    "'nhl_name',\n",
    " 'opposingTeam',\n",
    "'settled_in',\n",
    "'playoffGame',\n",
    "          'situation', \n",
    "             \n",
    "    'won',   \n",
    "'goalsAgainst',\n",
    " 'goalsFor',\n",
    "             \n",
    " 'penalityMinutesAgainst',\n",
    " 'penalityMinutesFor',\n",
    " 'penaltiesAgainst',\n",
    " 'penaltiesFor',\n",
    "'powerPlayGoals',\n",
    " 'powerPlayOpportunities',\n",
    "             \n",
    "'faceOffsWonAgainst',\n",
    " 'faceOffsWonFor',\n",
    "'faceOffWinPercentage', #filled in\n",
    "             \n",
    "'giveawaysAgainst',\n",
    " 'giveawaysFor',\n",
    "'dZoneGiveawaysAgainst',\n",
    " 'dZoneGiveawaysFor',\n",
    "    \n",
    " \n",
    " 'shotAttemptsAgainst',\n",
    " 'shotAttemptsFor',\n",
    "'unblockedShotAttemptsAgainst',\n",
    " 'unblockedShotAttemptsFor',\n",
    " 'shotsOnGoalAgainst',\n",
    " 'shotsOnGoalFor',\n",
    " 'savedShotsOnGoalAgainst',\n",
    " 'savedShotsOnGoalFor',\n",
    " 'savedUnblockedShotAttemptsAgainst',\n",
    " 'savedUnblockedShotAttemptsFor',\n",
    "             \n",
    " 'xFreezeAgainst',\n",
    " 'xFreezeFor',\n",
    " 'xGoalsAgainst',\n",
    " 'xGoalsFor',\n",
    " \n",
    "'scoreVenueAdjustedxGoalsAgainst',\n",
    " 'scoreVenueAdjustedxGoalsFor',\n",
    " \n",
    "'xGoalsPercentage',\n",
    " 'corsiPercentage', \n",
    "\n",
    "'fenwickPercentage',\n",
    "             \n",
    "    'flurryScoreVenueAdjustedxGoalsAgainst',\n",
    " 'flurryScoreVenueAdjustedxGoalsFor',\n",
    "    'highDangerxGoalsAgainst',\n",
    " 'highDangerxGoalsFor',\n",
    "'highDangerShotsAgainst',\n",
    " 'highDangerShotsFor',]\n",
    "\n",
    "sorted(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53790622-a038-4cbf-9b16-b5e6efdd9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['faceOffWinPercentage'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1cd6ff-a14b-49f8-b612-350eb5918626",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_Pis = ['goalsAgainst', 'goalsFor', 'goal_diff', 'goal_perc', 'PP%', 'PK%', 'sh%', 'sv%', 'win_streak_grouped_10', 'conference_standing_grouped_10','Fclose%', 'PDO'] \n",
    "\n",
    "feat_Pis_plus = ['goalsAgainst', 'goalsFor', 'goal_diff', 'goal_perc', 'PP%', 'PK%', 'sh%', 'sv%', 'win_streak', 'pts%', 'win%', 'Fclose%', 'PDO'] \n",
    "\n",
    "#features I need to do this ...\n",
    "feat_for_Pis = ['full_date','season', 'game_id', 'nhl_name','HoA','opposingTeam',  'goalsAgainst','goalsFor',\n",
    "'powerPlayGoals','powerPlayOpportunities',  'shotsOnGoalAgainst','shotsOnGoalFor','savedShotsOnGoalAgainst','savedShotsOnGoalFor', \n",
    "    'fenwickPercentage', 'won', 'settled_in',] \n",
    "  \n",
    "#'win_streak_grouped_10', 'conference_standing_grouped_10',\n",
    "#'PDO'  \n",
    "\n",
    "#targets \n",
    " #could later try to train classifier to predict this ... tough tho --> reg or no\n",
    "    \n",
    "\n",
    "extra = ['corsiPercentage', \n",
    "    'penaltiesAgainst',\n",
    " 'penaltiesFor', \n",
    "    'shotAttemptsAgainst',\n",
    " 'shotAttemptsFor',\n",
    "    'unblockedShotAttemptsAgainst',\n",
    " 'unblockedShotAttemptsFor', 'savedUnblockedShotAttemptsAgainst',\n",
    " 'savedUnblockedShotAttemptsFor',\n",
    " 'xGoalsPercentage','scoreVenueAdjustedxGoalsAgainst',\n",
    " 'scoreVenueAdjustedxGoalsFor','blockedShotAttemptsAgainst',\n",
    " 'blockedShotAttemptsFor',\n",
    "\n",
    " 'flurryAdjustedxGoalsAgainst',\n",
    " 'flurryAdjustedxGoalsFor',\n",
    " 'flurryScoreVenueAdjustedxGoalsAgainst',\n",
    " 'flurryScoreVenueAdjustedxGoalsFor',\n",
    " 'missedShotsAgainst',\n",
    " 'missedShotsFor',]\n",
    "\n",
    "\n",
    "\n",
    "feat_Pis = ['goalsAgainst', 'goalsFor', 'goal_diff', 'goal_perc', 'PP%', 'PK%', 'sh%', 'sv%', 'win_streak_grouped_10', 'conference_standing_grouped_10','Fclose%', 'PDO'] \n",
    "\n",
    "feat_for_Pis = ['full_date','season', 'game_id', 'nhl_name','HoA','opposingTeam',  'goalsAgainst','goalsFor',\n",
    "'powerPlayGoals','powerPlayOpportunities',  'shotsOnGoalAgainst','shotsOnGoalFor','savedShotsOnGoalAgainst','savedShotsOnGoalFor', \n",
    "    'fenwickPercentage', 'won', 'settled_in',] \n",
    "  \n",
    "###set Leung aside for now ... \n",
    "    \n",
    "feat_Leung = ['ID', 'Date', 'HomeTeam', 'AwayTeam', 'GDiff','GF%', 'CF%','CSh%',\n",
    "'CSv%', 'FF%','FSh%','FSv%','PDO','PENDiff','ShF%','SDiff','Sh%', 'Sv%','FOW%','W%','FavoritesW%', 'Result']\n",
    "\n",
    "\n",
    "feat_for_Leung  = ['full_date','season', 'game_id', 'nhl_name','HoA','opposingTeam',  'goalsAgainst','goalsFor',\n",
    "'powerPlayGoals','powerPlayOpportunities',  'shotsOnGoalAgainst','shotsOnGoalFor','savedShotsOnGoalAgainst','savedShotsOnGoalFor', \n",
    "    'fenwickPercentage', 'won', 'settled_in',] \n",
    "  \n",
    "extra = ['corsiPercentage', \n",
    "    'penaltiesAgainst',\n",
    " 'penaltiesFor', \n",
    "    'shotAttemptsAgainst',\n",
    " 'shotAttemptsFor',\n",
    "    'unblockedShotAttemptsAgainst',\n",
    " 'unblockedShotAttemptsFor', 'savedUnblockedShotAttemptsAgainst',\n",
    " 'savedUnblockedShotAttemptsFor',\n",
    " 'xGoalsPercentage','scoreVenueAdjustedxGoalsAgainst',\n",
    " 'scoreVenueAdjustedxGoalsFor','blockedShotAttemptsAgainst',\n",
    " 'blockedShotAttemptsFor',\n",
    "\n",
    " 'flurryAdjustedxGoalsAgainst',\n",
    " 'flurryAdjustedxGoalsFor',\n",
    " 'flurryScoreVenueAdjustedxGoalsAgainst',\n",
    " 'flurryScoreVenueAdjustedxGoalsFor',\n",
    " 'missedShotsAgainst',\n",
    " 'missedShotsFor',]\n",
    "    \n",
    "    \n",
    "feat_plus = ['full_date','season', 'game_id', 'nhl_name','HoA','opposingTeam',  'goalsAgainst','goalsFor', 'goal_diff', 'goal_perc', 'PP%', 'PK%', 'sh%', 'sv%',  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9ec25b-2ff0-4f87-902d-f30cee1d51ab",
   "metadata": {},
   "source": [
    "##checking the calculations done to make the data set \n",
    "\n",
    "Overall, the sums, differences, ratios, cumulative sums and cumulative avgs \n",
    "are working well! \n",
    "\n",
    "what I checked: (beginning of season for SJS and a little bit TBL, I  eye-balled and also checked a few with a calculator; end of season just eye-balled a few)\n",
    "\n",
    "The following problems were found:  [now fixed as of 7pm Aug 6]\n",
    "\n",
    "1. df_game_team_stats has around 40 games with 0 0 score (df_game is ok)\n",
    "note: they are all OT 1-0 games (from df_game) so these can be imputed using the \"won\" column (the game_ids are below)\n",
    "\n",
    "2. get_k_avg and get_k_sum need to loop over the team so that the dates are restricted to the fixed team (rather than all the last 10 dates regardless of whether the team played or not). This error messed up: wins in last 10 and stuff (counting ones also)\n",
    "\n",
    "3. the first game of teams starting after first game of season have a \n",
    "bad first row ... it should be NaN but instead it is same as game 2 ... after that no errors game 2 on ... so not big deal. Probably date = date0\n",
    "etc. is messed up in get_k_sum and get_k_avg ... probably looping over teams first will fix it like in 2.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e2a56-bbc2-4a88-880d-066928a27ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##check stats calculations first few games ... \n",
    "##part 1 ... goals for and against stats ... \n",
    "##they are all OT 1-0 wins ... so you can impute this using the \"won\" column\n",
    "\n",
    "X_12.loc[X_12['nhl_name'].isin(['SJS']), ['game_id','full_date', 'nhl_name', 'HoA', 'won', 'settled_in','games_so_far', 'goalsAgainst',  'goalsFor', 'goalsFor%', 'goalsDiff','goalsDiff_cumul_sum','goalsAgainst_cumul_sum',   'goalsFor_cumul_sum',    'goalsFor%_cumul_avg', \n",
    "   ]].iloc[:15, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd5f3b-ce76-48c0-9591-334729fc82ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'shotsOnGoalAgainst', 'shotsOnGoalFor', 'savedShotsOnGoalAgainst',\n",
    "       'savedShotsOnGoalFor', 'fenwickPercentage',    'sh%_cumul_avg', 'sv%_cumul_avg', 'PDO',  'PDO_cumul_avg'\n",
    "       'fenwickPercentage_cumul_avg',\n",
    "     'sh%', 'sv%', \n",
    "      'powerPlayGoals', 'powerPlayOpportunities',\n",
    "            'pp%', 'pk%', 'pp%_cumul_avg', 'pk%_cumul_avg',\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ecbd5-9a30-4e55-9166-0e92261b648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##check stats calculations first few games ... \n",
    "##part 4 ...shots, fenwick \n",
    "X_12.loc[X_12['nhl_name'].isin(['SJS']), ['game_id','full_date', 'nhl_name', 'HoA', 'won','goalsAgainst',  'goalsFor', \n",
    "       'powerPlayGoals', 'powerPlayOpportunities',\n",
    "            'pp%', 'pk%', 'pp%_cumul_avg', 'pk%_cumul_avg', ]].iloc[:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259f1119-b3ac-4b1a-b56f-7db49c84612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##check stats calculations first few games ... \n",
    "##part 3 ... pp, \n",
    "X_12.loc[X_12['nhl_name'].isin(['SJS']), ['game_id','full_date', 'nhl_name', 'HoA', 'won','goalsAgainst',  'goalsFor', \n",
    "       'shotsOnGoalAgainst', 'shotsOnGoalFor', 'savedShotsOnGoalAgainst', \n",
    "       'savedShotsOnGoalFor', 'sh%', 'sv%','PDO', 'PDO_cumul_avg','sh%_cumul_avg', 'sv%_cumul_avg', 'fenwickPercentage',     \n",
    "       'fenwickPercentage_cumul_avg',\n",
    "      ]].iloc[-8:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c27af-9841-436f-81ee-40e7b3b37058",
   "metadata": {},
   "outputs": [],
   "source": [
    "##check stats calculations first few games ... \n",
    "##part 2 ... wins, win% ...\n",
    "X_12.loc[X_12['nhl_name'].isin(['SJS']), ['game_id','full_date', 'nhl_name', 'HoA', 'won','goalsAgainst',  'goalsFor', \n",
    "       'won_cumul_sum', 'games_so_far', 'win%', 'ones','won_10_day_sum',\n",
    "       'ones_10_day_sum', 'last_10_games_win%', ]].iloc[:20, :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
