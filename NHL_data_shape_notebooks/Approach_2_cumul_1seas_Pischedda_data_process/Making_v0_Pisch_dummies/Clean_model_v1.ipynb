{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ef210bf-f076-4e91-abdb-68bb6d42f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "##couple evaluation functions \n",
    "def evaluate_binary_classification(model_name, y_test, y_pred, y_proba=None):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    #try:\n",
    "    if y_proba != None:\n",
    "        rocauc_score = roc_auc_score(y_test, y_proba)\n",
    "    else:\n",
    "        rocauc_score = \"no roc\"\n",
    "    #except: \n",
    "    #    pass     \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True)\n",
    "    plt.tight_layout()\n",
    "    plt.title(f'{model_name}', y=1.1)\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    print(\"accuracy: \", accuracy)\n",
    "    print(\"precision: \", precision)\n",
    "    print(\"recall: \", recall)\n",
    "    print(\"f1 score: \", f1)\n",
    "    print(\"rocauc: \", rocauc_score)\n",
    "    print(cm)\n",
    "    #return accuracy, precision, recall, f1, rocauc_score\n",
    "\n",
    "def evaluate_regression(y_test, y_pred):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(\"mae\", mae)\n",
    "    print(\"mse\", mse)\n",
    "    print('r2', r2)\n",
    "    \n",
    "##display null values\n",
    "\n",
    "\n",
    "def perc_null(X):\n",
    "    \n",
    "    total = X.isnull().sum().sort_values(ascending=False)\n",
    "    data_types = X.dtypes\n",
    "    percent = (X.isnull().sum()/X.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "    missing_data = pd.concat([total, data_types, percent], axis=1, keys=['Total','Type' ,'Percent'])\n",
    "    return missing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67563c90-f17d-4fec-b031-333748f3ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "##clean up df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feat_drop = [ \n",
    "'startRinkSide',\n",
    "'HoA',   #this is mp  ###many of these are repeated from mp_data\n",
    "'HoA_bet',\n",
    "'VH',\n",
    "'home_or_away',\n",
    "'team',\n",
    "'name',\n",
    "'Team',\n",
    "'Unnamed: 0',\n",
    "'playerTeam',\n",
    "'position',\n",
    "'blocked',  ## Same as bSAAgainst\n",
    "'pim', ## same as penaltyminFor\n",
    "'goals',  ##goalsFor\n",
    "'shots',\n",
    "'giveaways',\n",
    " 'hits',\n",
    "]    \n",
    "\n",
    "\n",
    "\n",
    "feat_rename = {'Date':'date', 'mp_date':'full_date', 'HoA_gm_stats':'HoA',  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee5ae41f-68fa-4db0-bbdb-88c6fb1b0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"/Users/joejohns/data_bootcamp/GitHub/final_project_nhl_prediction/Data/Shaped_Data/data_bet_stats_mp.csv\")\n",
    "data.drop(columns=[ 'Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9235c761-bb3f-473c-a73d-86f9e157e0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HoA',\n",
       " 'Open',\n",
       " 'blockedShotAttemptsAgainst',\n",
       " 'blockedShotAttemptsFor',\n",
       " 'corsiPercentage',\n",
       " 'dZoneGiveawaysAgainst',\n",
       " 'dZoneGiveawaysFor',\n",
       " 'date',\n",
       " 'faceOffWinPercentage',\n",
       " 'faceOffsWonAgainst',\n",
       " 'faceOffsWonFor',\n",
       " 'fenwickPercentage',\n",
       " 'flurryAdjustedxGoalsAgainst',\n",
       " 'flurryAdjustedxGoalsFor',\n",
       " 'flurryScoreVenueAdjustedxGoalsAgainst',\n",
       " 'flurryScoreVenueAdjustedxGoalsFor',\n",
       " 'freezeAgainst',\n",
       " 'freezeFor',\n",
       " 'full_date',\n",
       " 'game_id',\n",
       " 'giveawaysAgainst',\n",
       " 'giveawaysFor',\n",
       " 'goalsAgainst',\n",
       " 'goalsFor',\n",
       " 'head_coach',\n",
       " 'highDangerGoalsAgainst',\n",
       " 'highDangerGoalsFor',\n",
       " 'highDangerShotsAgainst',\n",
       " 'highDangerShotsFor',\n",
       " 'highDangerxGoalsAgainst',\n",
       " 'highDangerxGoalsFor',\n",
       " 'hitsAgainst',\n",
       " 'hitsFor',\n",
       " 'iceTime',\n",
       " 'lowDangerGoalsAgainst',\n",
       " 'lowDangerGoalsFor',\n",
       " 'lowDangerShotsAgainst',\n",
       " 'lowDangerShotsFor',\n",
       " 'lowDangerxGoalsAgainst',\n",
       " 'lowDangerxGoalsFor',\n",
       " 'mediumDangerGoalsAgainst',\n",
       " 'mediumDangerGoalsFor',\n",
       " 'mediumDangerShotsAgainst',\n",
       " 'mediumDangerShotsFor',\n",
       " 'mediumDangerxGoalsAgainst',\n",
       " 'mediumDangerxGoalsFor',\n",
       " 'missedShotsAgainst',\n",
       " 'missedShotsFor',\n",
       " 'nhl_name',\n",
       " 'opposingTeam',\n",
       " 'penalityMinutesAgainst',\n",
       " 'penalityMinutesFor',\n",
       " 'penaltiesAgainst',\n",
       " 'penaltiesFor',\n",
       " 'playContinuedInZoneAgainst',\n",
       " 'playContinuedInZoneFor',\n",
       " 'playContinuedOutsideZoneAgainst',\n",
       " 'playContinuedOutsideZoneFor',\n",
       " 'playStoppedAgainst',\n",
       " 'playStoppedFor',\n",
       " 'playoffGame',\n",
       " 'powerPlayGoals',\n",
       " 'powerPlayOpportunities',\n",
       " 'reboundGoalsAgainst',\n",
       " 'reboundGoalsFor',\n",
       " 'reboundsAgainst',\n",
       " 'reboundsFor',\n",
       " 'reboundxGoalsAgainst',\n",
       " 'reboundxGoalsFor',\n",
       " 'savedShotsOnGoalAgainst',\n",
       " 'savedShotsOnGoalFor',\n",
       " 'savedUnblockedShotAttemptsAgainst',\n",
       " 'savedUnblockedShotAttemptsFor',\n",
       " 'scoreAdjustedShotsAttemptsAgainst',\n",
       " 'scoreAdjustedShotsAttemptsFor',\n",
       " 'scoreAdjustedTotalShotCreditAgainst',\n",
       " 'scoreAdjustedTotalShotCreditFor',\n",
       " 'scoreAdjustedUnblockedShotAttemptsAgainst',\n",
       " 'scoreAdjustedUnblockedShotAttemptsFor',\n",
       " 'scoreFlurryAdjustedTotalShotCreditAgainst',\n",
       " 'scoreFlurryAdjustedTotalShotCreditFor',\n",
       " 'scoreVenueAdjustedxGoalsAgainst',\n",
       " 'scoreVenueAdjustedxGoalsFor',\n",
       " 'season',\n",
       " 'settled_in',\n",
       " 'shotAttemptsAgainst',\n",
       " 'shotAttemptsFor',\n",
       " 'shotsOnGoalAgainst',\n",
       " 'shotsOnGoalFor',\n",
       " 'situation',\n",
       " 'takeaways',\n",
       " 'takeawaysAgainst',\n",
       " 'takeawaysFor',\n",
       " 'team_id',\n",
       " 'totalShotCreditAgainst',\n",
       " 'totalShotCreditFor',\n",
       " 'unblockedShotAttemptsAgainst',\n",
       " 'unblockedShotAttemptsFor',\n",
       " 'won',\n",
       " 'xFreezeAgainst',\n",
       " 'xFreezeFor',\n",
       " 'xGoalsAgainst',\n",
       " 'xGoalsFor',\n",
       " 'xGoalsFromActualReboundsOfShotsAgainst',\n",
       " 'xGoalsFromActualReboundsOfShotsFor',\n",
       " 'xGoalsFromxReboundsOfShotsAgainst',\n",
       " 'xGoalsFromxReboundsOfShotsFor',\n",
       " 'xGoalsPercentage',\n",
       " 'xOnGoalAgainst',\n",
       " 'xOnGoalFor',\n",
       " 'xPlayContinuedInZoneAgainst',\n",
       " 'xPlayContinuedInZoneFor',\n",
       " 'xPlayContinuedOutsideZoneAgainst',\n",
       " 'xPlayContinuedOutsideZoneFor',\n",
       " 'xPlayStoppedAgainst',\n",
       " 'xPlayStoppedFor',\n",
       " 'xReboundsAgainst',\n",
       " 'xReboundsFor']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['won'] = data['won'].apply(int)\n",
    "data_playoffs = data.loc[data['playoffGame'] == 1, :].copy()  #set aside playoff games ... probably won't use them.\n",
    "data=  data.loc[data['playoffGame'] == 0, :].copy() \n",
    "\n",
    "sorted(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "176e3bfd-ced9-49b0-ae6a-5cf09464f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(X, season):  #season 20162017 int; returns the list of all dates in chronological order from that season 20161004, 20161005, ...\n",
    "    X = X.loc[X['season'] == season, :].copy()\n",
    "    dates_1 = list(set(X.loc[(X['date'] >= 900) & (X['date'] <= 1231) , :]['full_date']))  #2016 part\n",
    "    dates_2 = list(set(X.loc[(X['date'] >= 100) & (X['date'] <= 800) , :]['full_date']))  #2017 part\n",
    "    dates = dates_1 + dates_2 #all dates in order\n",
    "    return dates\n",
    "\n",
    "#sorted(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ee3407a6-3cac-4048-a729-686abd489ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = get_dates(data, 20162017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "81c4bffe-9d3a-441b-9951-ff4022a37b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_HA_data(X, season, list_var_names = None ):\n",
    "    X = X.loc[X['season'] == season, :].copy()\n",
    "    X_H = X.loc[X['HoA'] == 'home',:].copy()\n",
    "    X_A = X.loc[X['HoA'] == 'away',:].copy()\n",
    "    X_H['goal_difference'] = X_H['goalsFor'] - X_H['goalsAgainst']  ##note every thing is based in home data\n",
    "    X_H.reset_index(drop = True, inplace = True)\n",
    "    X_A.reset_index(drop = True, inplace = True)\n",
    "    df_visitor = pd.get_dummies(X_H['nhl_name'], dtype=np.int64)\n",
    "    df_home = pd.get_dummies(X_A['nhl_name'], dtype=np.int64)\n",
    "    df_model = df_home.sub(df_visitor) \n",
    "    df_model['date'] = X_H['date']\n",
    "    df_model['full_date'] = X_H['full_date']\n",
    "    \n",
    "    df_model['game_id'] = X_H['game_id']\n",
    "    df_model['home_id'] = X_H['team_id']\n",
    "    df_model['away_id'] = X_A['team_id'] \n",
    "    y = X_H.loc[:,['date', 'full_date','game_id', 'Open','goal_difference', 'won']].copy()   ##these are from home team perspective; 'Open' is for betting \n",
    "    return (df_model, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc96680-15be-4c1a-969a-e06377f0d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_model_results(model,model_name, window_size, prediction_size)\n",
    "    results_dic ={}\n",
    "    results_dic['date'] = []\n",
    "    results_dic['mae'] = []\n",
    "    results_dic['mse'] = []\n",
    "    results_dic['r2'] = []\n",
    "    for i in range(step, len(dates), step): ##step =10, so 17 rounds\n",
    "        model.fit(X.loc[X['mp_date'].isin(dates[i-step:i]), :], y.loc[y['mp_date'].isin(dates[i-step:i]),'goal_difference' ] )\n",
    "        model.fit(X.loc[X['mp_date'].isin(dates[max(i-win,0):i]), :],y.loc[y['mp_date'].isin(dates[max(i-win,0):i]),'goal_difference' ])\n",
    "        y_pred = lr1.predict(X.loc[X['mp_date'].isin(dates[i:i+pred]), :])\n",
    "        y2_pred = lr2.predict(X.loc[X['mp_date'].isin(dates[i:i+pred]), :])\n",
    "        y1_pred_win = v_make_win(y1_pred)\n",
    "        y2_pred_win = v_make_win(y2_pred)                    \n",
    "        y_test = y.loc[y['mp_date'].isin(dates[i:i+pred]),'goal_difference' ]\n",
    "        y_test_win = y.loc[y['mp_date'].isin(dates[i:i+pred]),'won' ]\n",
    "    \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test_win, y_pred)\n",
    "        \n",
    "        \n",
    "    results_dic['date'] = []\n",
    "    results_dic['mae'] = []\n",
    "    results_dic['mse'] = []\n",
    "    results_dic['r2'] = []   \n",
    "    results_dic['model_name'].append(model_name)\n",
    "    results_dic['date'].append(dates[i])\n",
    "    \n",
    "    \n",
    "    #results_dic['predictions'].append(y1_pred)\n",
    "    #results_dic['actual'].append(y_test)\n",
    "    mae = mean_absolute_error(y_test, y1_pred)\n",
    "    mse = mean_squared_error(y_test, y1_pred)\n",
    "    r2 = r2_score(y_test_win, y1_pred_win)\n",
    "    accuracy = accuracy_score(y_test_win, y1_pred_win)\n",
    "    precision = precision_score(y_test_win, y1_pred_win, zero_division = 0)\n",
    "    recall = recall_score(y_test_win, y1_pred_win)\n",
    "    f1 = f1_score(y_test_win, y1_pred_win)\n",
    "                          \n",
    "                          \n",
    "    results_dic['mae'].append(mae)\n",
    "    results_dic['mse'].append(mse)\n",
    "    results_dic['r2'].append(r2)\n",
    "          \n",
    "    #preds_dic['model_version'].append(\"RidgeReg(C=0.001)_ONE_day\")\n",
    "    #preds_dic['date'].append(dates[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebbc1299-df52-4305-891e-fb47150baa6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3598ea1f-e60b-46a8-a6da-a52e4c898438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top3_max_val_params(model, X, dates, drop_firs=False):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d4647-c363-417c-95e2-f68b49533cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fir regressors predicting wins - losses, can use this to turn output into win prediction \n",
    "\n",
    "def make_win(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >0:\n",
    "        return 1\n",
    "\n",
    "v_make_win = np.vectorize(make_win)\n",
    "\n",
    "#v_make_win(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d61e6a4f-fe63-4ef8-9771-e10c342f3990",
   "metadata": {},
   "outputs": [],
   "source": [
    "##note KNN or other clusters might be helpful group the teams in smart way ... but not now.\n",
    "\n",
    "\n",
    "\n",
    "#models\n",
    "\n",
    "##regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#classifiers (non-tree)\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#tree-based classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "##regression models\n",
    "lr = Ridge(alpha=0.001) \n",
    "rfr = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "xgbr = XGBRegressor()\n",
    "\n",
    "##classifier models\n",
    "lrc = RidgeClassifier()\n",
    "gnb = GaussianNB()\n",
    "lgr = LogisticRegression(random_state = 0)\n",
    "svc = SVC()\n",
    "\n",
    "#tree-based classifiers\n",
    "rfc =  RandomForestClassifier(max_depth=3, random_state=0)\n",
    "bc = BaggingClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d1290-9ccf-4769-b472-1cce549d1b5b",
   "metadata": {},
   "source": [
    "\n",
    "##hyper_parameters from here \n",
    "##https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "##for xgboost from here \n",
    "##https://machinelearningmastery.com/extreme-gradient-boosting-ensemble-in-python/\n",
    "\n",
    "#xgb\n",
    "\n",
    "trees = [10, 50, 100, 500, 1000, 5000]  #100  #num of trees\n",
    "max_depth = range(1,11)  ##3-5\n",
    "rates = [0.0001, 0.001, 0.01, 0.1, 1.0]  #0.1\n",
    "subsample in arange(0.1, 1.1, 0.1):  #0.4, 0.5  ##this is 0.1, 0.2 ... 1.0 # % of features to sample\n",
    "\n",
    "\n",
    "#svc \n",
    "kernels in [‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’] #if you use poly, then adjust degree\n",
    "C in [100, 10, 1.0, 0.1, 0.001]\n",
    "\n",
    "#gb\n",
    "\n",
    "learning_rate in [0.001, 0.01, 0.1]\n",
    "n_estimators [10, 100, 1000]\n",
    "subsample in [0.5, 0.7, 1.0]\n",
    "max_depth in [3, 7, 9]\n",
    "\n",
    "\n",
    "#rfc\n",
    "max_features [1 to 20]  #key\n",
    "max_features in [‘sqrt’, ‘log2’]\n",
    "n_estimators in [10, 100, 1000]\n",
    "\n",
    "#bc\n",
    "n_estimators in [10, 100, 1000]\n",
    "\n",
    "svm_dic = {'kernels':[‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’]}\n",
    "lrc_dic = {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "lgr_hp_dic = {'solver': [‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’], 'penalty' : [‘none’, ‘l1’, ‘l2’, ‘elasticnet’],\n",
    "'C' :[100, 10, 1.0, 0.1, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c1e6410-c03d-4efc-9baa-11abaf1411ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##part 1\n",
    "##use models with default\n",
    "##use data set with H/A +1, -1\n",
    "##do full window for now\n",
    "\n",
    "##next:\n",
    "##check if just excluding first 10 days helps (chaotic)\n",
    "##check if different windows help\n",
    "\n",
    "##next\n",
    "## can try tuning (for loops by hand, or ... use grid_search (use ML mastery code))\n",
    "##-I think tuning will be faster ... just do by hand ... loop over the possible things \n",
    "##-ONE for loop over i = (a,b,c,d)... for each model i[0]\n",
    "\n",
    "##Orrr can try adding features ... here we have to worry about:\n",
    "##-adding basic features eg pp, and correct fo%\n",
    "##-scaling numericals\n",
    "##-dummy vars for categoricals (are there any?) besides H/A\n",
    "##-num_windows and which lengths for moving avgs\n",
    "##-filtering the features for increasing complexity inteligently\n",
    "##-There is a dicotemy: \n",
    "##(a)use H/A + numerics or  ... here I think it can be made more like time-series\n",
    "##(b) just use mumerics (moving avg) ... here I think the order of the games is not important (note Leung did this, and random train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "251b8645-53e5-401d-b47d-18d014827882",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = make_HA_data(data, 20162017)[0]\n",
    "y = make_HA_data(data, 20162017)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2295f7ef-0d4c-413a-bddf-b0108a596d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [('lrc',lrc), ('gnb', gnb), ('lgr', lgr), ('svc',svc), ('rfc', rfc), ('bc', bc),  ('gbc', gbc), ] # ('xgbc',  xgbc)]\n",
    "\n",
    "##start with small list \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "00db2934-4889-46e6-9df7-02df8fa533df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157    1\n",
       "158    0\n",
       "159    1\n",
       "160    1\n",
       "161    1\n",
       "      ..\n",
       "294    1\n",
       "295    0\n",
       "296    0\n",
       "297    1\n",
       "298    1\n",
       "Name: won, Length: 142, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y.loc[y['full_date'].isin(dates[10: 30]), 'won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ffacee18-7fba-4730-82ad-b12efdcfe4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5428571428571428"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svc.fit(X.loc[X['full_date'].isin(dates[10: 30]), :], y.loc[y['full_date'].isin(dates[10: 30]), 'won'])\n",
    "y_pred = svc.predict(X.iloc[600:, :])\n",
    "y_test = y.iloc[600:, 5]\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bd60230f-e238-463c-bd5b-6a950dd9c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3066bba4-c6d2-4c69-b781-5b872370d499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    342\n",
       "0    288\n",
       "Name: won, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X.iloc[0:600, :], y.iloc[0:600, 5])\n",
    "y_pred = svc.predict(X.iloc[600:, :])\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bfa3db4c-8b79-45a7-9c7c-5682319ac106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_model_results(model, model_name, X, dates, step, window_size, prediction_size, drop_first_k_days = 0): #X = data \n",
    "    results_dic['date'] = []\n",
    "    results_dic['mae'] = []\n",
    "    results_dic['mse'] = []\n",
    "    results_dic['r2'] = []   \n",
    "    \n",
    "    \n",
    "    #drop first k days from dates and X\n",
    "    dates = dates[drop_first_k_days :]\n",
    "    X = X.loc[X['full_date'].isin(dates), :].copy()  \n",
    "\n",
    "    for i in range(step, len(dates), step): ##eg step =10, so 17 rounds\n",
    "        model.fit(X.loc[X['full_date'].isin(dates[max(i-window_size ,0):i]), :],y.loc[y['full_date'].isin(dates[max(i-window_size,0):i]),'goal_difference' ])\n",
    "        y_pred = model.predict(X.loc[X['full_date'].isin(dates[i:i+prediction_size]), :])\n",
    "        y_test = y.loc[y['full_date'].isin(dates[i:i+prediction_size]),'goal_difference' ]\n",
    "    \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        #recision = precision_score(y_test, y_pred, zero_division = 0)\n",
    "        #recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average = None)\n",
    "            \n",
    "        \n",
    "        results_dic['model_name'].append(model_name)\n",
    "        results_dic['date'].append(dates[i])\n",
    "    \n",
    "        results_dic['mae'].append(mae)\n",
    "        results_dic['mse'].append(mse)\n",
    "        results_dic['r2'].append(r2)\n",
    "        \n",
    "    return results_dic #!\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7feab800-3d32-4b69-83ae-8014962c34cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6666666666666665"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array([1,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c9989ff4-4152-488c-b97a-ca030013199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_model_results(model, model_name, X, dates, step, window_size, prediction_size, drop_first_k_days = 0): #X = data \n",
    "    results_dic ={}\n",
    "    results_dic['model_name'] = []\n",
    "    results_dic['date'] = []\n",
    "    results_dic['accuracy'] = []\n",
    "    results_dic['f1_score'] = []\n",
    "\n",
    "    #results_dic['precision'] = []\n",
    "  #  results_dic['recall'] = []\n",
    "    \n",
    "    #drop first k days from dates and X\n",
    "    dates = dates[drop_first_k_days :]\n",
    "    X = X.loc[X['full_date'].isin(dates), :].copy()  \n",
    "\n",
    "    for i in range(step, len(dates), step): ##eg step =10, so 17 rounds\n",
    "        model.fit(X.loc[X['full_date'].isin(dates[max(i-window_size ,0):i]), :],y.loc[y['full_date'].isin(dates[max(i-window_size,0):i]),'won' ])\n",
    "        y_pred = model.predict(X.loc[X['full_date'].isin(dates[i:i+prediction_size]), :])\n",
    "        y_test = y.loc[y['full_date'].isin(dates[i:i+prediction_size]),'won' ]\n",
    "    \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        #recision = precision_score(y_test, y_pred, zero_division = 0)\n",
    "        #recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred) #, average = None)\n",
    "            \n",
    "        results_dic['model_name'].append(model_name)  #append same model name every iter so same length as others\n",
    "        results_dic['date'].append(dates[i])\n",
    "                          \n",
    "        results_dic['accuracy'].append(accuracy)\n",
    "        results_dic['f1_score'].append(f1)\n",
    "        #results_dic['precision'].append(precision)\n",
    "        #results_dic['recall'].append(recall)\n",
    "    results_dic['model_name'].append('model_name'+'_avg')  #append same model name every iter so same length as others\n",
    "    results_dic['date'].append('average')\n",
    "    results_dic['accuracy'].append(round(np.mean(np.array(results_dic['accuracy'])), 2) ) \n",
    "    results_dic['f1_score'].append(round(np.mean(np.array(results_dic['f1_score'])), 2) ) \n",
    "    return results_dic #!\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3554dd1b-eab4-4c9e-927e-a4bc6bab2a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4509b68a-1604-4060-8594-d3e7653fed4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20170104, 20170105, 20170106, 20170107, 20170108]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates[120:125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2ba5b3cf-949e-4141-a7cc-5efec1d6326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you X.loc[X['full_date'].isin(dates[120:125]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "577f44dd-ac29-4c81-8186-81914f3f874a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [4 5 6 7 8 9]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-61e1fe842452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#y_pred = svc.predict(X.loc[X['full_date'].isin(dates[25:25+5]), :])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprediction_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprediction_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_le'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_indexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcolumn_indexes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    161\u001b[0m                     \"y contains previously unseen labels: %s\" % str(diff))\n\u001b[1;32m    162\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [4 5 6 7 8 9]"
     ]
    }
   ],
   "source": [
    "##debigging (dates had playoff games in it )\n",
    "\n",
    "step = 20\n",
    "prediction_size = 5\n",
    "for i in range(step, len(dates), step): \n",
    "    #y_pred = svc.predict(X.loc[X['full_date'].isin(dates[25:25+5]), :])\n",
    "    y_pred = xgbc.predict(X.loc[X['full_date'].isin(dates[i:i+prediction_size]), :])\n",
    "    print(i, i+prediction_size, y_pred[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a46b7dd4-be49-4aed-a397-c5341761bd9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "value 0 for Parameter num_class should be greater equal to 1\nnum_class: Number of output class in the multi-class classification.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-219-bc16d922825e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod_nm_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod_nm_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mresults_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_model_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_size\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_first_k_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mall_results_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_dic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-216-da46bb47fc8f>\u001b[0m in \u001b[0;36mclass_model_results\u001b[0;34m(model, model_name, X, dates, step, window_size, prediction_size, drop_first_k_days)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m##eg step =10, so 17 rounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwindow_size\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'won'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprediction_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mprediction_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'won'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    907\u001b[0m             eval_group=None, label_transform=label_transform)\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         self._Booster = train(xgb_options, train_dmatrix,\n\u001b[0m\u001b[1;32m    910\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                               \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \"\"\"\n\u001b[0;32m--> 227\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    228\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: value 0 for Parameter num_class should be greater equal to 1\nnum_class: Number of output class in the multi-class classification."
     ]
    }
   ],
   "source": [
    "all_results_dic = {}\n",
    "xgb_param = xgbc.get_xgb_params()\n",
    "xgb_param['num_class'] = 2\n",
    "\n",
    "for mod_nm_pair in [('xgbc', xgbc)]:  #models_list:\n",
    "    model_name = mod_nm_pair[0]\n",
    "    model = mod_nm_pair[1]\n",
    "    results_dic = class_model_results(model=model, model_name=model_name, X = X, dates = dates, step = 20, window_size =75, prediction_size =5, drop_first_k_days = 0)\n",
    "    all_results_dic[model_name] = results_dic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "aaea5a0f-9e95-441d-95c0-28329adf9ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res_df_dic ={}\n",
    "\n",
    "for name in all_results_dic.keys():\n",
    "    res_df_dic[name] = pd.DataFrame(all_results_dic[name])\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8f702497-e19a-4a9e-82f9-58a64b3e1a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = list(res_df_dic.keys())[0]\n",
    "df_all_results = pd.DataFrame(res_df_dic[name1])\n",
    "\n",
    "for name in list(res_df_dic.keys())[1:]:\n",
    "    df_all_results = pd.concat([df_all_results, res_df_dic[name]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4ee24277-02a4-4396-8249-bbd5f4b49c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>date</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bc</td>\n",
       "      <td>20170104</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bc</td>\n",
       "      <td>20170124</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bc</td>\n",
       "      <td>20170217</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bc</td>\n",
       "      <td>average</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gbc</td>\n",
       "      <td>20161114</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.731707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gbc</td>\n",
       "      <td>20161204</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.711111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gbc</td>\n",
       "      <td>20161227</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.558140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gbc</td>\n",
       "      <td>20170304</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gbc</td>\n",
       "      <td>20170324</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.680851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gbc</td>\n",
       "      <td>20170104</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gbc</td>\n",
       "      <td>20170124</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gbc</td>\n",
       "      <td>20170217</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gbc</td>\n",
       "      <td>average</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name      date  accuracy  f1_score\n",
       "5         bc  20170104  0.513514  0.571429\n",
       "6         bc  20170124  0.500000  0.500000\n",
       "7         bc  20170217  0.472222  0.344828\n",
       "8         bc   average  0.520000  0.540000\n",
       "0        gbc  20161114  0.645161  0.731707\n",
       "1        gbc  20161204  0.617647  0.711111\n",
       "2        gbc  20161227  0.547619  0.558140\n",
       "3        gbc  20170304  0.454545  0.608696\n",
       "4        gbc  20170324  0.605263  0.680851\n",
       "5        gbc  20170104  0.594595  0.615385\n",
       "6        gbc  20170124  0.454545  0.538462\n",
       "7        gbc  20170217  0.583333  0.482759\n",
       "8        gbc   average  0.560000  0.620000"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_results.iloc[50:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c07e9f4b-a420-48f3-92eb-88bf11bcd3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy    0.520851\n",
       "dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_dic['svc'].iloc[:,2:].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "666cccf4-cc46-423a-a301-c771b9f749cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20170228"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2acedde-c505-4c50-b9f5-eeedfa536740",
   "metadata": {},
   "source": [
    "##why is accuracy so bad last date? lgr and svc have some decent results around 0.6 (over all 0.52)\n",
    "\n",
    "\n",
    "#check how lr does ...as classifier and regression ... see if it's still at 58, 59 % ... and if not\n",
    "#what needs to change to get it back? only new thing is window, step, predict_size params ...\n",
    "#could also do naive train on first half text on second as I did at first ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##xgbc needs to have num_class =2 ... can either switch to xgbr and use \n",
    "\n",
    "#params = { \"objective\": \"multi:softmax\", 'num_class': 2} ## ! 3}\n",
    "#model = xgb.XGBRegressor(**params)\n",
    "\n",
    "#or you can stick with xgbc and use cv instead of fit\n",
    "\n",
    "xgb_param = model.get_xgb_params()\n",
    "    extra = {'num_class': 3}\n",
    "    xgb_param.update(extra)\n",
    "    cvresult = xgb.cv(xgb_param, xgtrain, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f0a0f6-0824-4f35-929f-0cc16333f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "##part 1\n",
    "##use models with default\n",
    "##use data set with H/A +1, -1\n",
    "##do full window for now\n",
    "\n",
    "##next:\n",
    "##check if just excluding first 10 days helps (chaotic)\n",
    "##check if different windows help\n",
    "\n",
    "##next\n",
    "## can try tuning (for loops by hand, or ... use grid_search (use ML mastery code))\n",
    "##-I think tuning will be faster ... just do by hand ... loop over the possible things \n",
    "##-ONE for loop over i = (a,b,c,d)... for each model i[0]\n",
    "\n",
    "#probably do features (below) next ... it's time to bring in some serious features now that \n",
    "#the basic infrastructure for quick evaluation is set up ....\n",
    "#then I will probably write some optimizer loops over windows, models, and feature sets\n",
    "\n",
    "##Orrr can try adding features ... here we have to worry about:\n",
    "##-adding basic features eg pp, and correct fo%\n",
    "##-scaling numericals\n",
    "##-dummy vars for categoricals (are there any?) besides H/A\n",
    "##-num_windows and which lengths for moving avgs\n",
    "##-filtering the features for increasing complexity inteligently\n",
    "##-There is a dicotemy: \n",
    "##(a)use H/A + numerics or  ... here I think it can be made more like time-series\n",
    "##(b) just use mumerics (moving avg) ... here I think the order of the games is not important (note Leung did this, and random train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
