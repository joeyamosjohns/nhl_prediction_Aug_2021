{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1130d59f-24e9-4a16-bbce-084382e6a362",
   "metadata": {},
   "source": [
    "Some basic tests are performed here with the aim of doing gradual learning as the season goes on using either \n",
    "model.fit() [retrain every period]\n",
    "model.partialfit() [remember old training and train only on new games; this is available only for some models; even creme, special module only has some models]\n",
    "\n",
    "Conclusion: Preliminary tests along these lines are not promising, as accuracy scores are in the 52-53% range which is quite bad.\n",
    "It is possible that introdusing different features may help or that this method is more sensitive to tuning of hyper-parameters, \n",
    "so may revisit later. Pischedda obtained much better results (59-60% accuracy) using a similar method so should do better\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41cf42f-b7b4-4804-88ff-4231435dc65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f07197c-4595-4a0f-a52d-3592e15a4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes the odds eg -200 is the favorite, 140 is underdog and says fav wins \n",
    "\n",
    "def fav_win(x):\n",
    "    if x <=0:\n",
    "        return 1\n",
    "    if x>0:\n",
    "        return 0\n",
    "    \n",
    "v_fav_win = np.vectorize(fav_win)\n",
    "\n",
    "\n",
    "def make_win(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >0:\n",
    "        return 1\n",
    "\n",
    "v_make_win = np.vectorize(make_win)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615fac1a-dba5-473c-9975-967397a6e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = {}\n",
    "\n",
    "file_path_12 = '/Users/joejohns/data_bootcamp/GitHub/nhl_prediction_Aug_2021B/Data/Processed_Data/Approach_1 and_2_win_loss_and_cumul_1seas_Pisch_data/shaped_Pisch_data_xg_added/data_dummies_Pis_v2_20122013.csv'\n",
    "data_dic[20122013] = pd.read_csv(file_path_12)\n",
    "\n",
    "for season in [20152016, 20162017, 20172018, 20182019]:   \n",
    "    \n",
    "    file_path_seas = '/Users/joejohns/data_bootcamp/GitHub/nhl_prediction_Aug_2021B/Data/Processed_Data/Approach_1 and_2_win_loss_and_cumul_1seas_Pisch_data/shaped_Pisch_data_xg_added/data_dummies_Pis_xg_Corsi_v3_'+str(season)+'.csv'\n",
    "    data_dic[season] = pd.read_csv(file_path_seas)\n",
    " # data_bootcamp/GitHub/final_project_nhl_prediction/Note_books/Explore_Models/data_dummies_Pis_v2_20122013.csv\n",
    "#data_bootcamp/GitHub/final_project_nhl_prediction/Note_books/Explore_Models/data_dummies_Pis_xg_Corsi_v3_20152016.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae3c8a-2f09-4dd2-9c6c-d06ffe155738",
   "metadata": {},
   "source": [
    "##probably better to just do all seasons in one big file ... can do that later\n",
    "\n",
    "all_seasons = sorted(set(data['season']))\n",
    "all_seasons\n",
    "\n",
    "X_dic = {}\n",
    "y_dic = {}\n",
    "for sea in all_seasons:\n",
    "   X_dic[sea] = make_HA_data(data, sea)[0]\n",
    "   y_dic[sea] = make_HA_data(data, sea)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671ac399-6ba6-4da6-8b0b-9b2d8842c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for  regressors predicting wins - losses, can use this to turn output into win prediction \n",
    "\n",
    "def make_win(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >0:\n",
    "        return 1\n",
    "\n",
    "v_make_win = np.vectorize(make_win)\n",
    "\n",
    "#useage: v_make_win(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8178cf0e-79a1-4190-bac6-756431e4eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "k =5\n",
    "for season in [20122013,20152016, 20162017, 20172018, 20182019]:    \n",
    "    filter = (data_dic[season]['full_date'] >= data_dic[season]['full_date'][0]+k).copy() #removes first k = 5 days of season where there are nan values \n",
    "    data_dic[season]= data_dic[season].loc[filter, :].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "308a54d3-0bcc-4f3e-a9a1-3d83bdbb8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_12 = data_dic[20122013].copy()  \n",
    "data_15 = data_dic[20152016].copy()\n",
    "data_16  = data_dic[20162017].copy()\n",
    "data_17 = data_dic[20172018].copy()\n",
    "data_18 = data_dic[20182019].copy()\n",
    "data_15_17 = pd.concat([data_15,data_16])\n",
    "data_17_19 = pd.concat([data_17,data_18])\n",
    "#Note Bene\n",
    "data_12.rename(columns ={'win%':'win%_cumul'}, inplace = True)\n",
    "data_12.rename(columns ={'last_10_games_win%' :'win%_last_10_games'}, inplace = True)\n",
    "#(1230, 50)\n",
    "#(1230, 50)\n",
    "#(1271, 51) Vegas, baby\n",
    "#(1271, 51)'win%_last_10_games'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e36bc47-9881-40b4-b278-2e351df5f59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'game_id', 'full_date', 'home_team', 'away_team', 'Open',\n",
       "       'goal_difference', 'won'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_target = list(data_15.iloc[:5, :8].columns)\n",
    "data_15.iloc[:5, :8].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d1b54d8-04f9-43b8-8ea9-fdc05491e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_12 = data_12.iloc[:,7:].copy() \n",
    "X_15 = data_15.drop(columns = columns_target ).copy()\n",
    "X_16 = data_16.drop(columns = columns_target ).copy()\n",
    "X_17 = data_17.drop(columns = columns_target ).copy()\n",
    "X_18 = data_18.drop(columns = columns_target ).copy()\n",
    "y_12 = data_12.iloc[:,:7].copy() \n",
    "y_15 = data_15.loc[:, columns_target ].copy()\n",
    "y_16 = data_16.loc[:, columns_target ].copy()\n",
    "y_17 = data_17.loc[:, columns_target ].copy()\n",
    "y_18 = data_18.loc[:, columns_target ].copy()\n",
    "list_X = [X_12, X_15,X_16, X_17, X_18]\n",
    "list_y = [y_12, y_15, y_16,y_17, y_18 ]\n",
    "list_Xy = zip(list_X, list_y)\n",
    "list_data = [data_12, data_15, data_16, data_17, data_18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62a6fc67-d452-471d-bd03-58ff98af4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "##note KNN or other clusters might be helpful group the teams in smart way ... but not now.\n",
    "#models\n",
    "\n",
    "##regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#classifiers (non-tree)\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#tree-based classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bd765ca-f8e6-4c7e-9f22-2c62736af562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##regression models\n",
    "lr = Ridge(alpha=0.001) \n",
    "rfr = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "xgbr = XGBRegressor()\n",
    "sgdr = SGDRegressor() #has partial_fit()\n",
    "\n",
    "##classifier models\n",
    "lrc = RidgeClassifier()\n",
    "gnb = GaussianNB()  #has partial_fit()\n",
    "lgr = LogisticRegression(random_state = 0, max_iter = 10**5)\n",
    "svc = SVC()\n",
    "sgdc = SGDClassifier() #has partial_fit()\n",
    "\n",
    "#tree-based classifiers\n",
    "rfc =  RandomForestClassifier(max_depth=3, random_state=0)\n",
    "bc = BaggingClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "xgbc = XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "##have partial_fit()\n",
    "\n",
    "\n",
    "#['BernoulliNB', 'GaussianNB', 'MiniBatchKMeans', 'MultinomialNB', 'PassiveAggressiveClassifier', PassiveAggressiveRegressor', 'Perceptron', 'SGDClassifier', 'SGDRegressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8733fce-f91a-4955-ac8a-f3df7f7549c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "std_scal = StandardScaler()\n",
    "mm_scal = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdd54ca6-2df5-452c-b72a-2a06b2ddbeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['goalsAgainst_cumul_sum', 'goalsFor_cumul_sum', 'goalsDiff_cumul_sum',\n",
       "       'goalsFor%_cumul_avg', 'pp%_cumul_avg', 'pk%_cumul_avg',\n",
       "       'sh%_cumul_avg', 'sv%_cumul_avg', 'PDO_cumul_avg',\n",
       "       'fenwickPercentage_cumul_avg', 'win%_last_10_games', 'win%_cumul'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_scale = list(data_15.iloc[:5, 38:].columns)\n",
    "data_15.iloc[:5, 38:].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96959348-597c-4f72-bfcf-d4cc5e5855c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'game_id', 'full_date', 'home_team', 'away_team', 'Open',\n",
       "       'goal_difference', 'won'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_target = list(data_15.iloc[:5, :8].columns)\n",
    "data_15.iloc[:5, :8].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1162c17-80a7-4f3a-9c51-100141c2bd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02346027,  0.27487007,  0.21805609, ..., -0.45399568,\n",
       "         0.5798809 ,  0.62311823],\n",
       "       [-0.12258815, -0.62634327, -0.35220268, ..., -0.23861609,\n",
       "        -1.21075221, -1.30087212],\n",
       "       [ 0.67043491, -0.06308493, -0.5965993 , ..., -0.971329  ,\n",
       "        -1.80762991, -1.94220223],\n",
       "       ...,\n",
       "       [-0.41997179,  0.61282507,  0.78831487, ..., -0.67734162,\n",
       "         0.34112982,  0.80635541],\n",
       "       [-1.60950638, -1.75285995,  0.05512502, ...,  1.5316141 ,\n",
       "        -0.37512342,  0.27038667],\n",
       "       [-1.41125061, -0.51369161,  0.78831487, ...,  1.59684997,\n",
       "        -0.73325005,  0.21183044]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experimenting with std_scaler ... \n",
    "#NOte Bene ... you must assign the numpy object std_scal.fit_transform(Y.loc[:,columns_to_scale]).copy()\n",
    "#to the df ... if you assign pd.DataFrame(same) it will give NaNs (why?)\n",
    " \n",
    "Y = X_12.iloc[:300, :].copy()\n",
    "#Y.loc[:,columns_to_scale] = pd.DataFrame(std_scal.fit_transform(Y.loc[:,columns_to_scale])).copy()\n",
    "Y.loc[:,columns_to_scale] = std_scal.fit_transform(Y.loc[:,columns_to_scale]).copy()\n",
    "Y.loc[:,columns_to_scale]\n",
    "Y2 = X_12.iloc[300:, :].copy()\n",
    "Y2.loc[:,columns_to_scale] = std_scal.transform(Y2.loc[:,columns_to_scale])\n",
    "#X_12.iloc[300:, :]\n",
    "\n",
    "#are these two scalars independent? yes ... but this doesn't work if you do std_scal = Sta ...  and use that ... bec std_scal is one instance\n",
    "scal = StandardScaler()\n",
    "scal_T = StandardScaler()\n",
    "\n",
    "\n",
    "Y = X_12.iloc[:300, :].copy()\n",
    "Y_T = X_12.iloc[300:, :].copy()\n",
    "\n",
    "#Y.loc[:,columns_to_scale] = pd.DataFrame(std_scal.fit_transform(Y.loc[:,columns_to_scale])).copy()\n",
    "#scal.fitY.loc[:,columns_to_scale])\n",
    "scal.fit(Y.loc[:,columns_to_scale])\n",
    "scal_T.fit(Y_T.loc[:,columns_to_scale])\n",
    "\n",
    "scal.transform(Y.loc[:,columns_to_scale])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2987d5-a55a-4038-91c7-a143ec8aab21",
   "metadata": {},
   "source": [
    "Next cell we try 2015-16 and all models ... training up to T = 800 and predicting d =100 (vary these T,d ... see if anything is good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae336cc8-9633-4c23-9cbd-0aa4c95dd656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier()  TEST accuracy  0.51 test f1 0.588235294117647\n",
      "GaussianNB()  TEST accuracy  0.53 test f1 0.591304347826087\n",
      "LogisticRegression(max_iter=100000, random_state=0)  TEST accuracy  0.46 test f1 0.55\n",
      "SVC()  TEST accuracy  0.51 test f1 0.6141732283464567\n",
      "RandomForestClassifier(max_depth=3, random_state=0)  TEST accuracy  0.53 test f1 0.6802721088435373\n",
      "BaggingClassifier()  TEST accuracy  0.44 test f1 0.4166666666666667\n",
      "GradientBoostingClassifier()  TEST accuracy  0.56 test f1 0.6206896551724138\n",
      "[17:18:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, verbosity=None)  TEST accuracy  0.45 test f1 0.46601941747572817\n"
     ]
    }
   ],
   "source": [
    "T = 800  #train until this game in season (out of 1200)\n",
    "d = 100  #predict this many games \n",
    "scal = std_scal\n",
    "#X_15 has about 1200 games\n",
    "\n",
    "#set the data frame and target\n",
    "X = X_15.copy()\n",
    "y = y_15.loc[:, 'won'].copy()\n",
    "\n",
    "#how does it predict on next season?? Terrible! lol ... train around 80% test 47%\n",
    "#W = X_16.copy()\n",
    "#z = y_16.loc[:, 'won'].copy()\n",
    "\n",
    "for model in [lrc,  gnb, lgr, svc,  rfc, bc, gbc, xgbc]:\n",
    "    y_train= y.iloc[:T].copy()\n",
    "    y_test = y.iloc[T:T+d].copy()\n",
    "    #y_test = z.iloc[:100].copy()\n",
    "\n",
    "    X_train = X.iloc[:T, :].copy()\n",
    "    X_test= X.iloc[T:T+d, :].copy()   \n",
    "    #X_test = W.iloc[:100].copy()\n",
    "    \n",
    "    #do standard/minmax scaling on X_train numeric columns ... better to do pipeline? \n",
    "    #X_train.loc[:, columns_to_scale] = scal.fit_transform(X_train.loc[:, columns_to_scale]).copy()\n",
    "    \n",
    "    #fit the scaler from train portion to the test portion \n",
    "    #X_test.loc[:, columns_to_scale] = scal.transform(X_test.loc[:, columns_to_scale]).copy()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "  \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    \n",
    "    print(model, ' TEST accuracy ', acc, 'test f1', f1)\n",
    "    \n",
    "    y_pred_train_err =  model.predict(X_train) #! careful with this code\n",
    "    f1_train_err = f1_score(y_train,y_pred_train_err)\n",
    "    acc_train_err = accuracy_score(y_train, y_pred_train_err)\n",
    "    #print(' training error ', model, acc_train_err, ) #f1_train_err)\n",
    "   \n",
    "   \n",
    "#I am following this stackexchange\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#In [93]: mms = MinMaxScaler()\n",
    "#In [94]: df[['x','z']] = mms.fit_transform(df[['x','z']])\n",
    "#the one with check mark does pipe line tho :-) https://stackoverflow.com/questions/43834242\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d35d0cf-ce42-4ecc-9638-1d54e0cde243",
   "metadata": {},
   "source": [
    "Next we try varying d, for a few fixed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1539690-9ffc-48b5-ab5a-69c071f440bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB() NOO partial_fit avg train error  0.6732921003851697  AVERAGE TEST ERROR  0.5282051282051281\n"
     ]
    }
   ],
   "source": [
    "#T = 800  #train until this game in season (out of 1200)\n",
    "d = 20  #predict this many games \n",
    "scal = StandardScaler() \n",
    "#X_15 has about 1200 games\n",
    "\n",
    "#set the data frame and target\n",
    "X = X_15.copy()\n",
    "y = y_15.loc[:, 'won'].copy()\n",
    "\n",
    "model = gnb\n",
    "#model = sgdc\n",
    "##quick checks \n",
    "\n",
    "counter = 0\n",
    "acc_sum_train = 0\n",
    "acc_sum_test = 0\n",
    "#for model in [gnb, sgdc]:  #partial_fit\n",
    "for T in range(d, 800,d):\n",
    "    y_train= y.iloc[:T].copy()\n",
    "    y_test = y.iloc[T:T+d].copy()\n",
    "    #y_test = z.iloc[:100].copy()\n",
    "\n",
    "    X_train = X.iloc[:T, :].copy()\n",
    "    X_test= X.iloc[T:T+d, :].copy()   \n",
    "    #X_test = W.iloc[:100].copy()\n",
    "    \n",
    "    #do standard/minmax scaling on X_train numeric columns ... better to do pipeline? \n",
    "    X_train.loc[:, columns_to_scale] = scal.fit_transform(X_train.loc[:, columns_to_scale]).copy()\n",
    "    \n",
    "    #fit the scaler from train portion to the test portion \n",
    "    X_test.loc[:, columns_to_scale] = scal.transform(X_test.loc[:, columns_to_scale]).copy()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "  \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    \n",
    "    y_pred_train_err =  model.predict(X_train) #! careful with this code\n",
    "    f1_train_err = f1_score(y_train,y_pred_train_err)\n",
    "    acc_train_err = accuracy_score(y_train, y_pred_train_err)\n",
    "    #print(' training error ', model, acc_train_err, ) #f1_train_err)\n",
    "   \n",
    "    \n",
    "    #print(model, ' train error ', acc_train_err, ' f1_train ', f1_train_err, ' TEST ERROR ', acc, ' f1 ', f1)\n",
    "    acc_sum_test += acc\n",
    "    acc_sum_train += acc_train_err\n",
    "    counter +=1\n",
    "avg_acc = acc_sum_test/counter\n",
    "avg_acc_train = acc_sum_train/counter\n",
    "print(model, 'NOO partial_fit' ' avg train error ', avg_acc_train, ' AVERAGE TEST ERROR ', avg_acc,)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc056b3b-6091-4dcf-b1f6-bb0e7dd9cfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier() NOO partial_fit avg train error  0.6330287399645583  AVERAGE TEST ERROR  0.5120240480961924\n",
      "SGDClassifier() with partial_fit   avg train accuracy  0.8557114228456913  AVERAGE TEST accuracy (acc, acc_T)  0.5190380761523046 0.5280561122244489\n"
     ]
    }
   ],
   "source": [
    "#### \n",
    "D= 1000 #train until this game in season (out of 1200)\n",
    "d = 2  #predict this many games \n",
    "scal = StandardScaler() \n",
    "#X_15 has about 1200 games\n",
    "\n",
    "#set the data frame and target\n",
    "X = X_15.copy()\n",
    "y = y_15.loc[:, 'won'].copy()\n",
    "\n",
    "#model_np = GaussianNB()\n",
    "#model= GaussianNB()\n",
    "model_np = SGDClassifier()\n",
    "##quick checks \n",
    "\n",
    "counter = 0\n",
    "acc_sum_train_np = 0\n",
    "acc_sum_test_np = 0\n",
    "#for model in [gnb, sgdc]:  #partial_fit\n",
    "for T in range(d, D,d):\n",
    "    y_train= y.iloc[:T].copy()\n",
    "    y_test = y.iloc[T:T+d].copy()\n",
    "    #y_test = z.iloc[:100].copy()\n",
    "\n",
    "    X_train = X.iloc[:T, :].copy()\n",
    "    X_test= X.iloc[T:T+d, :].copy()   \n",
    "    #X_test = W.iloc[:100].copy()\n",
    "    \n",
    "    #do standard/minmax scaling on X_train numeric columns ... better to do pipeline? \n",
    "    X_train.loc[:, columns_to_scale] = scal.fit_transform(X_train.loc[:, columns_to_scale]).copy()\n",
    "    \n",
    "    #fit the scaler from train portion to the test portion \n",
    "    X_test.loc[:, columns_to_scale] = scal.transform(X_test.loc[:, columns_to_scale]).copy()\n",
    "    \n",
    "    model_np.fit(X_train, y_train)\n",
    "    y_pred = model_np.predict(X_test)\n",
    "  \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    #f1 = f1_score(y_test,y_pred)\n",
    "    \n",
    "    y_pred_train_err =  model_np.predict(X_train) #! careful with this code\n",
    "   # f1_train_err = f1_score(y_train,y_pred_train_err)\n",
    "    acc_train_err = accuracy_score(y_train, y_pred_train_err)\n",
    "    #print(' training error ', model, acc_train_err, ) #f1_train_err)\n",
    "   \n",
    "    \n",
    "    #print(model, ' train error ', acc_train_err, ' f1_train ', f1_train_err, ' TEST ERROR ', acc, ' f1 ', f1)\n",
    "    acc_sum_test_np += acc\n",
    "    acc_sum_train_np += acc_train_err\n",
    "    counter +=1\n",
    "avg_acc_np = acc_sum_test_np/counter\n",
    "avg_acc_train_np = acc_sum_train_np/counter\n",
    "print(model, 'NOO partial_fit' ' avg train error ', avg_acc_train_np, ' AVERAGE TEST ERROR ', avg_acc_np,)\n",
    "   \n",
    "\n",
    "#T = 800  #train until this game in season (out of 1200)\n",
    "#d = 20  #predict this many games \n",
    "\n",
    "#two independent scalers, one for <=T, one for T-d, T\n",
    "scal = StandardScaler()\n",
    "scal_T = StandardScaler()\n",
    "\n",
    "#X_15 has about 1200 games\n",
    "\n",
    "#set the data frame and target\n",
    "#X = X_16.copy()\n",
    "#y = y_16.loc[:, 'won'].copy()\n",
    "\n",
    "#model = gnb\n",
    "#model = sgdc\n",
    "##quick checks \n",
    "\n",
    "#for model in [gnb, sgdc]:  #partial_fit\n",
    "counter = 0\n",
    "acc_sum_train = 0\n",
    "acc_sum_test = 0\n",
    "acc_sum_test_T = 0\n",
    "for T in range(d, D ,d):\n",
    "    y_train= y.iloc[T-d:T].copy()\n",
    "    y_test = y.iloc[T:T+d].copy()\n",
    "    #y_test = z.iloc[:100].copy()\n",
    "\n",
    "    X_train = X.iloc[T-d:T, :].copy()\n",
    "    X_scaling_T = X.iloc[:T, :].copy()  #use this to scale the test data ... if we use T-d to T scaler will fluctuate a lot.\n",
    "    X_test= X.iloc[T:T+d, :].copy() \n",
    "    X_test_T= X.iloc[T:T+d, :].copy() \n",
    "    #X_test = W.iloc[:100].copy()\n",
    "    \n",
    "    #do standard/minmax scaling on X_train numeric columns ... better to do pipeline? \n",
    "    X_train.loc[:, columns_to_scale] = scal.fit_transform(X_train.loc[:, columns_to_scale]).copy()\n",
    "    \n",
    "    #fit the scaler on all < = T and use this to transform [T to T+d] (and try not as well)\n",
    "    scal_T.fit(X_scaling_T.loc[:, columns_to_scale])\n",
    "    X_test_T.loc[:, columns_to_scale] = scal_T.transform(X_test_T.loc[:, columns_to_scale]).copy()\n",
    "    X_test.loc[:, columns_to_scale] = scal.transform(X_test.loc[:, columns_to_scale]).copy()\n",
    "    \n",
    "    model.partial_fit(X_train, y_train, classes=np.unique([1,0]))\n",
    "    y_pred_T = model.predict(X_test_T)\n",
    "    y_pred = model.predict(X_test)\n",
    "  \n",
    "    acc_T = accuracy_score(y_test, y_pred_T)\n",
    "    acc= accuracy_score(y_test, y_pred)\n",
    "    #f1 = f1_score(y_test,y_pred)\n",
    "    \n",
    "    y_pred_train_err =  model.predict(X_train) #! careful with this code\n",
    "    #f1_train_err = f1_score(y_train,y_pred_train_err)\n",
    "    acc_train_err = accuracy_score(y_train, y_pred_train_err)\n",
    "    #print(' training error ', model, acc_train_err, ) #f1_train_err)\n",
    "   \n",
    "    \n",
    "    #print(model, 'with partial_fit ', ' train error ', acc_train_err, ' f1_train ', f1_train_err, ' TEST ERROR ', acc, ' f1 ', f1)\n",
    "    acc_sum_test += acc\n",
    "    acc_sum_test_T += acc_T\n",
    "    acc_sum_train += acc_train_err\n",
    "    counter +=1\n",
    "avg_acc = acc_sum_test/counter\n",
    "avg_acc_T = acc_sum_test_T/counter\n",
    "avg_acc_train = acc_sum_train/counter\n",
    "#dic[D] = [D, avg_acc_train,  avg_acc, avg_acc_T, avg_acc_np]\n",
    "#print(dic[D])\n",
    "print(model, 'with partial_fit ', ' avg train accuracy ', avg_acc_train, ' AVERAGE TEST accuracy (acc, acc_T) ', avg_acc, avg_acc_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06292432-6699-494c-b366-004f9de6a3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
