{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5748a4fb-d564-4aef-ae66-36aeb62688fb",
   "metadata": {},
   "source": [
    "In this noteboook we do a rudimentary betting strategy. There was some struggle to even get a even positive ROI \n",
    "\n",
    "with different attempts so this is a reasonable baseline of 5% and 10% ROI in 2016-17 and 2017-18 respectively for logistic regression \n",
    "\n",
    "I will attempt a more sophisticated approach which considers: \n",
    "1. the home/away, favorite/not favorite situation (in our calculation below we can see that away/underdog is a losing bet in general, for example\n",
    "2. the model predicted probability vs the betting implied probability (strictly speaking, breaking even or better long term is impossible unless pred_proba >= implied_proba) \n",
    "3. one can also look at model confidence as a measure of distance of probabaility from 0.5 (eg 0.6 high confifdence, 0.51 low confidence)\n",
    "\n",
    "I attempted these already, but there was something wrong in the calculations so I dropped them for the time being in \n",
    "favour of this simpler approach.\n",
    "\n",
    "Certainly, one expectes to do better using a more sophisticated approach.\n",
    "\n",
    "Then as usual there is model selection which may improve the betting results (this betting result is just for logisistic regressio at the moment)\n",
    "... and the various ways we expect to improve the models in the model development stage (tuning, feature selection, \n",
    "introducing neural net model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c51fe7-3295-4fb1-b20b-80db247c8331",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0925f991-38da-4544-99ce-ca44a1a1230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##note KNN or other clusters might be helpful group the teams in smart way ... but not now.\n",
    "#models\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "std_scal = StandardScaler()\n",
    "mm_scal = MinMaxScaler()\n",
    "\n",
    "\n",
    "##no tuning \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, f1_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "##regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#classifiers (non-tree)\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#tree-based classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37eb0dc6-4652-47a5-b49e-8b03e89d5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "##helper functions\n",
    "\n",
    "def fav_pred(x):\n",
    "    if x < 0:\n",
    "        return 1\n",
    "    if x>0:\n",
    "        return 0\n",
    "    if x==0:\n",
    "        print(\"O odds detected, nan returned\")\n",
    "        return np.NaN\n",
    "v_fav_pred = np.vectorize(fav_pred)\n",
    "\n",
    "\n",
    "def implied_proba(odds):\n",
    "    if odds > 0: \n",
    "        return 100/(odds+100)    #bet 100 to get 100+odds; profit = odds\n",
    "    \n",
    "#def fav_implied_proba(odds):\n",
    "    if odds < 0:\n",
    "        return (-odds)/(-odds + 100)   #bet |odds| to get 100+|odds|; profit = 100\n",
    "    \n",
    "v_impl_proba = np.vectorize(implied_proba)\n",
    "\n",
    "def are_equal(x1,x2):  # 1 if nums =1, 0, o/w  #delta \n",
    "    return int(x1 == x2)\n",
    "v_are_equal = np.vectorize(are_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a999e42-d252-4b8f-a55a-295591148828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10385, 26)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('/Users/joejohns/data_bootcamp/GitHub/nhl_prediction_Aug_2021B/Data/Processed_Data/Approach_3_bulk_Leung_data/data_LJ.csv')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8042150-3246-48b5-bd4c-fa9fb56acb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['goal_diff_target'] = X['home_goals'] - X['away_goals']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88f882dd-902a-4ac6-a246-b76bcc42d49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'game_id', 'mp_date', 'season', 'home_team', 'away_team',\n",
       "       'home_odds', 'away_odds', 'home_goals', 'away_goals', 'home_win',\n",
       "       'settled_in', 'CF%', 'CSh%', 'CSv%', 'FF%', 'FSh%', 'FSv%', 'GDiff',\n",
       "       'GF%', 'PDO', 'PENDiff', 'SF%', 'SDiff', 'Sh%', 'Sv',\n",
       "       'goal_diff_target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will use this for correlations etc at the bottom\n",
    "\n",
    "data = X.copy()\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5940dcf3-fc38-4e3c-8275-c2f1957d233c",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "X['season'] = X['season'].apply(int)\n",
    "X['game_id'] = X['game_id'].apply(int)\n",
    "X['mp_date'] = X['mp_date'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd4bf90-9e6f-4d38-ae4c-bf42d1a42c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9104, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt_no_early  = (X['mp_date'].apply(lambda x : x% 10**4) < 900) | (1100 < X['mp_date'].apply(lambda x : x% 10**4))\n",
    "\n",
    "X = X.loc[filt_no_early, : ].copy()  ## keep games < 900 and > 1100\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a6e69f5-8d38-4dee-baac-a7dbd2d1bdcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20162017    1060\n",
       "20172018    1052\n",
       "20142015    1046\n",
       "20112012    1037\n",
       "20152016    1036\n",
       "20132014     994\n",
       "20082009     971\n",
       "20102011     962\n",
       "20092010     946\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6286444-30ac-4c26-8357-1f6165e9d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9104, 27)\n",
      "(9104, 27)\n",
      "(7859, 27)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "\n",
    "filt_no_early  = (X['mp_date'].apply(lambda x : x% 10**4) < 900) | (1100 < X['mp_date'].apply(lambda x : x% 10**4))\n",
    "X= X.loc[filt_no_early, : ].copy()  ## keep games < 900 and > 1100\n",
    "print(X.shape)\n",
    "filt_no_fav = (v_fav_pred(X['home_odds']) != v_fav_pred(X['away_odds'])).copy() \n",
    "X.loc[filt_no_fav, :]['season'].value_counts()\n",
    "X = X.loc[ filt_no_fav , : ].copy()  #1000 plus rows across all seasons \n",
    "print(X.shape)\n",
    "##below we see we lose approx 10% dropping games before nov 1 and another 10% where the betting odds are messed up (both negative)\n",
    "##could use different betting odds or try to fix these ones later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df3b1740-1790-4c92-8566-a76bc58b012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#woof two 10% loses\n",
    "X.reset_index(inplace = True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a151c17a-25ed-45b4-82fb-776587adb09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = ['Unnamed: 0', 'game_id', 'mp_date', 'season', 'home_team', 'away_team',\n",
    "       'home_odds', 'away_odds', 'home_goals', 'away_goals', 'goal_diff_target', 'home_win',\n",
    "       'settled_in', ]\n",
    "\n",
    "x_cols = ['CF%', 'CSh%', 'CSv%', 'FF%', 'FSh%', 'FSv%', 'GDiff',\n",
    "       'GF%', 'PDO', 'PENDiff', 'SF%', 'SDiff', 'Sh%', 'Sv']\n",
    "columns_to_scale = ['CF%', 'CSh%', 'CSv%', 'FF%', 'FSh%', 'FSv%', 'GDiff',\n",
    "       'GF%', 'PDO', 'PENDiff', 'SF%', 'SDiff', 'Sh%', 'Sv']  ##same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6414781d-187c-445f-8259-9b6dd043dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x = np.array(X.loc[(X['season'] <= 20152016), x_cols].copy())\n",
    "  #features test-train\n",
    "Y = X.loc[(X['season'] <= 20152016), y_cols].copy()\n",
    "   #targets\n",
    "y = np.array(Y['home_win']).reshape(-1,1)\n",
    "\n",
    "\n",
    "              \n",
    "x_16 = X.loc[(X['season'] == 20162017), x_cols].copy()  #features test-train\n",
    "Y_16 = X.loc[(X['season'] == 20162017), y_cols].copy()   #targets\n",
    "y_16 = np.array(Y_16['home_win']).reshape(-1,1)\n",
    "\n",
    "x_17 = X.loc[(X['season'] == 20172018), x_cols].copy()  #features test-train\n",
    "Y_17 = X.loc[(X['season'] == 20172018), y_cols].copy()   #targets\n",
    "y_17 = np.array(Y_17['home_win']).reshape(-1,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4981f86b-36d5-4717-93b0-902f2d5cafe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20162017    922\n",
       "20172018    904\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[(X['season'] >= 20162017), :]['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75aac508-e1e7-45e9-bc70-1b4410435bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20142015    933\n",
       "20082009    902\n",
       "20152016    901\n",
       "20132014    846\n",
       "20112012    833\n",
       "20102011    810\n",
       "20092010    808\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[(X['season'] <= 20152016), :]['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c41671d3-d487-4cd1-a8f2-5c2f3f5bf27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6033"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[(X['season'] <= 20152016), :]['season'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b50b2130-1915-49f9-a594-8d347079bb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7859, 28)\n",
      "(6033, 14) (6033, 13) (6033, 1)\n",
      "(922, 14) (922, 1)\n",
      "(904, 14) (904, 1)\n",
      "sum of  6033 922 904  is:  7859\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(x.shape, Y.shape, y.shape)\n",
    "print(x_16.shape, y_16.shape)\n",
    "print(x_17.shape, y_17.shape)\n",
    "print('sum of ', y.shape[0],y_16.shape[0], y_17.shape[0], ' is: ', y.shape[0] + y_16.shape[0]+y_17.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "249c7aad-4a68-4904-88fd-d83eca5da2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20142015    933\n",
       "20082009    902\n",
       "20152016    901\n",
       "20132014    846\n",
       "20112012    833\n",
       "20102011    810\n",
       "20092010    808\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "110c6918-445b-44a0-997f-c8339ff0d264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20162017    922\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_16['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6439cd9-ad94-4db3-8e81-defc790c7f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20172018    904\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_17['season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9eacbbf6-2dc2-472f-838d-475f5f835c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler \n",
    "std_scal = StandardScaler()\n",
    "mm_scal = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bc682fa-87bd-4081-8dbd-ad4750ae1f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC() TEST:  0.5898922949461475\n",
      "RidgeClassif TEST:  0.5890637945318973\n",
      "RandomForest TEST:  0.536039768019884\n",
      "GaussianNB() TEST:  0.579950289975145\n",
      "LogisticRegr TEST:  0.584092792046396\n",
      "BaggingClass TEST:  0.5219552609776305\n",
      "GradientBoos TEST:  0.5749792874896438\n",
      "[20:34:47] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joejohns/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifie TEST:  0.531897265948633\n"
     ]
    }
   ],
   "source": [
    "###NOT tuned \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=314, stratify=y)\n",
    "\n",
    "#do standard/minmax scaling on X_train numeric columns ... better to do pipeline? \n",
    "x_train_sc = std_scal.fit_transform(x_train)\n",
    "    \n",
    "#fit the scaler from train portion to the test portion \n",
    "x_test_sc = std_scal.transform(x_test)\n",
    "##classifier models\n",
    "lrc2 = RidgeClassifier(alpha =0.001)\n",
    "gnb2 = GaussianNB()\n",
    "lgr2 = LogisticRegression(random_state = 0, max_iter = 500)\n",
    "svc2 = SVC(kernel = 'rbf')\n",
    "\n",
    "#tree-based classifiers\n",
    "rfc2 =  RandomForestClassifier( random_state=0)\n",
    "bc2 = BaggingClassifier()\n",
    "gbc2 = GradientBoostingClassifier()\n",
    "xgbc2 = XGBClassifier()\n",
    "##quick checks \n",
    "for model in [svc2, lrc2, rfc2, gnb2, lgr2, bc2, gbc2, xgbc2]:\n",
    "    model.fit(x_train_sc, y_train.ravel())\n",
    "      #model.fit(x_train_sc, y_train.ravel())\n",
    "    y_pred= model.predict(x_test_sc)\n",
    "    y_predt= model.predict(x_train_sc)  \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "   # f1 = f1_score(y_test,y_pred)\n",
    "    acct = accuracy_score(y_train, y_predt)\n",
    "    #f1t = f1_score(y_train,y_predt)\n",
    "  \n",
    "  \n",
    "    print(str(model)[0:12], 'TEST: ', acc ) #, f1, 'training : ', acct, f1t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "278be3dd-a12a-491d-9b50-534cd56adbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC() 20162017, no tuning, TEST:  0.5954446854663774 0.6965012205044753\n",
      "RidgeClassif 20162017, no tuning, TEST:  0.596529284164859 0.6940789473684211\n",
      "RandomForest 20162017, no tuning, TEST:  0.5563991323210412 0.6209453197405005\n",
      "GaussianNB() 20162017, no tuning, TEST:  0.588937093275488 0.6393910561370123\n",
      "LogisticRegr 20162017, no tuning, TEST:  0.5997830802603037 0.6962962962962963\n",
      "BaggingClass 20162017, no tuning, TEST:  0.5249457700650759 0.5503080082135524\n",
      "GradientBoos 20162017, no tuning, TEST:  0.5780911062906724 0.6694987255734919\n",
      "XGBClassifie 20162017, no tuning, TEST:  0.5563991323210412 0.6130558183538316\n"
     ]
    }
   ],
   "source": [
    "#check on 2016\n",
    "x_16_sc = std_scal.transform(x_16).copy()\n",
    "x_test2 = std_scal.transform(x_16).copy()\n",
    "y_test2 = y_16.copy()\n",
    "\n",
    "\n",
    "##quick checks \n",
    "for model in [svc2, lrc2, rfc2, gnb2, lgr2, bc2, gbc2, xgbc2]:\n",
    "    #model.fit(x_train)\n",
    "      #model.fit(x_train_sc, y_train.ravel())\n",
    "    y_pred= model.predict(x_test2)\n",
    "  \n",
    "    acc = accuracy_score(y_test2, y_pred)\n",
    "    f1 = f1_score(y_test2,y_pred)\n",
    "   \n",
    "   \n",
    "    #acct = accuracy_score(y_train, y_predt)\n",
    "    #f1t = f1_score(y_train,y_predt)\n",
    "  \n",
    "  \n",
    "    print(str(model)[0:12], '20162017, no tuning, TEST: ', acc, f1) #, 'training : ', acct, f1t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cab9e96-8d30-42c2-b82b-32cec93099cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC() 20172018, no tuning, TEST:  0.6150442477876106 0.7293934681181959\n",
      "RidgeClassif 20172018, no tuning, TEST:  0.6183628318584071 0.7264076130055512\n",
      "RandomForest 20172018, no tuning, TEST:  0.5641592920353983 0.64568345323741\n",
      "GaussianNB() 20172018, no tuning, TEST:  0.5851769911504425 0.6524559777571826\n",
      "LogisticRegr 20172018, no tuning, TEST:  0.6183628318584071 0.7259729944400317\n",
      "BaggingClass 20172018, no tuning, TEST:  0.5232300884955752 0.5694305694305695\n",
      "GradientBoos 20172018, no tuning, TEST:  0.6106194690265486 0.7161290322580646\n",
      "XGBClassifie 20172018, no tuning, TEST:  0.5707964601769911 0.6472727272727273\n"
     ]
    }
   ],
   "source": [
    "#check on 2017\n",
    "\n",
    "x_test2 = std_scal.transform(x_17).copy()\n",
    "y_test2 = y_17.copy()\n",
    "\n",
    "\n",
    "##quick checks \n",
    "for model in [svc2, lrc2, rfc2, gnb2, lgr2, bc2, gbc2, xgbc2]:\n",
    "    #model.fit(x_train)\n",
    "      #model.fit(x_train_sc, y_train.ravel())\n",
    "    y_pred= model.predict(x_test2)\n",
    "  \n",
    "    acc = accuracy_score(y_test2, y_pred)\n",
    "    f1 = f1_score(y_test2,y_pred)\n",
    "    acc = accuracy_score(y_test2, y_pred)\n",
    "    f1 = f1_score(y_test2,y_pred)\n",
    "   \n",
    "    #acct = accuracy_score(y_train, y_predt)\n",
    "    #f1t = f1_score(y_train,y_predt)\n",
    "  \n",
    "  \n",
    "    print(str(model)[0:12], '20172018, no tuning, TEST: ', acc, f1) #, 'training : ', acct, f1t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0169381-d55a-42d6-90b7-3f78cb2fc8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pay_off(df_test):\n",
    "\n",
    "    df = df_test.copy()\n",
    "    \n",
    "    ##bet fav_home \n",
    "    df2 = df.loc[ (df_test['fav_pred'] !=  df_test['model_pred'])&(df_test['model_pred'] ==1), :]\n",
    "    df2['bet'] = 100\n",
    "    df2['win'] = df2['actual_res']*(  100*(1/df2['home_impl_proba']) + 100    )\n",
    "    df2['profit'] = df2['win'] - df2['bet']\n",
    "    \n",
    "    ##bet fav_away\n",
    "    df3= df.loc[ (df_test['fav_pred'] !=  df_test['model_pred'])&(df_test['model_pred'] == 0), :]\n",
    "    df3['bet'] = 100\n",
    "    df3['win'] = (1-df3['actual_res'])*(100*(1/df3['away_impl_proba']) + 100 )\n",
    "    df3['profit'] = df3['win'] - df3['bet']\n",
    "    \n",
    "    ##bet und_home \n",
    "    df4 = df.loc[ (df_test['fav_pred'] ==  df_test['model_pred'])&(df_test['model_pred'] ==1), :]\n",
    "    df4['bet'] = -df4['home_odds']\n",
    "    df4['win'] = df4['actual_res']*(-df['home_odds'] + 100) \n",
    "    df4['profit'] = df4['win'] - df4['bet']\n",
    "    \n",
    "    df5 =df.loc[ (df_test['fav_pred'] ==  df_test['model_pred'])&(df_test['model_pred'] == 0), :]\n",
    "    df5['bet'] =  -df5['away_odds']\n",
    "    df5['win'] = (1-df5['actual_res'])*(-df5['away_odds'] + 100) \n",
    "    df5['profit'] = df5['win'] - df5['bet']\n",
    "    \n",
    "    print(df5['profit'].sum(), (df5['profit'].sum() +   df5['bet'].sum())/df5['bet'].sum()        )\n",
    "    print(df2['profit'].sum(), (df2['profit'].sum() +   df2['bet'].sum())/df2['bet'].sum()        )\n",
    "    print(df3['profit'].sum(), (df3['profit'].sum() +   df3['bet'].sum())/df3['bet'].sum()        )                                    \n",
    "    print(df4['profit'].sum(), (df4['profit'].sum() +   df4['bet'].sum())/df4['bet'].sum()        )\n",
    "    profit_t = df2['profit'].sum()+df3['profit'].sum()+df4['profit'].sum() +df5['profit'].sum()\n",
    "    bet_t = df2['bet'].sum()+df3['bet'].sum() +df4['bet'].sum()+df5['bet'].sum()\n",
    "    \n",
    "    print(bet_t, profit_t, (profit_t+bet_t)/bet_t    )                                 \n",
    "                                    \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97998984-2a76-42b2-8536-88cb5ac23f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6133, 14)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###baseline pretraining accuracy when model says to bet fav and bet und\n",
    "###find some baselines from Y\"\n",
    "df_base = Y.copy()\n",
    "df_base['fav_pred'] = v_fav_pred(df_base['home_odds'] ).copy()\n",
    "df_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ecb8148d-3e1f-4735-85f8-0ac8f7526ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5949767834529337 0.567741935483871\n"
     ]
    }
   ],
   "source": [
    "fav_home_acc = ((df_base['home_win'] == 1)&(df_base['fav_pred'] == 1)).sum()/(df_base['fav_pred'] == 1).sum()\n",
    "und_home_acc = ((df_base['home_win'] == 0)&(df_base['fav_pred'] == 0)).sum()/(df_base['fav_pred'] == 0).sum()\n",
    "print(fav_home_acc, fav_away_acc)\n",
    "\n",
    "#accuracy if you bet for favorite home team, or favorite away team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995559d-6d71-4c5a-bef7-ce1d769a1ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "247eefaa-dea5-48a3-84c7-34d306ce3c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.584092792046396"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select model lgr2 logistic regression\n",
    "model = lgr2\n",
    "\n",
    "##quick check on model accuracy ... decent at 58.4%\n",
    "\n",
    "\n",
    "y_pred= model.predict(x_test_sc)  #this is <= 20152016 data\n",
    "acc_pre = accuracy_score(y_test, y_pred)  #this x_test_sc needs to be defined already above during training session on <=2015\n",
    "acc_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f15fab5-3c54-4360-bca4-f95779bb52e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def make_bet_df(model=model, x = x_16, y = y_16, Y = Y_16):\n",
    "    dic = {}  #x_16, lgr 0.55 ... Request rfc 0.58 x_16 and 0.6 on x_17 (later)\n",
    "    \n",
    "    dic['model_name'] = str(model)[0:10]\n",
    "    dic['actual_res'] = [ t[0] for t in list(y)]\n",
    "    dic['model_pred'] = list(model.predict(x))\n",
    "    \n",
    "    \n",
    "    dic['model_conf_1'] = [round(t,4) for t in model.predict_proba(x)[0:, 1]]\n",
    "    dic['model_conf_0'] =[round(t,4) for t in model.predict_proba(x)[0:, 0]]\n",
    "    \n",
    "    dic['home_odds'] = list(Y['home_odds'])\n",
    "    dic['away_odds'] = list(Y['away_odds'])\n",
    "    \n",
    "    df= pd.DataFrame(dic)\n",
    "    \n",
    "    \n",
    "    df['home_impl_proba'] = v_impl_proba(df['home_odds'])\n",
    "    df['away_impl_proba'] = v_impl_proba(df['away_odds'])\n",
    "    \n",
    "    df['conf_1_sub_home_impl'] = df['model_conf_1'] - df['home_impl_proba']\n",
    "    df['conf_0_sub_away_impl'] = df['model_conf_0'] - df['away_impl_proba']\n",
    "    \n",
    "    df['pre_acc_sub_home_impl'] = (acc_pre - df['home_impl_proba']).copy()\n",
    "    df['pre_acc_sub_away_impl'] = (acc_pre  - df['away_impl_proba']).copy()\n",
    "    \n",
    "    df['fav_pred'] = v_fav_pred(df['home_odds'] )\n",
    "    df['model_conf'] = (0.5)*(df['model_conf_1'] - df['model_conf_0'])\n",
    "    df['model_conf'] = np.abs(df['model_conf'])\n",
    "    return df   #df_bet_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "797a65f2-f647-49de-bd45-bbdc6f83b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test17 = make_bet_df(model=model, x = x_17, y = y_17, Y = Y_17)\n",
    "df_test  = make_bet_df(model=model, x = x_16, y = y_16, Y = Y_16)   ##this is for model = rfc and season = 20162017; rfc dif well on both seasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4acdc2-de6a-431b-ade1-e784833ffa41",
   "metadata": {},
   "source": [
    "We investigate a few baselines for the model ... betting against or for the betting favorite, and  in the case of both home and away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e4754bc-faa0-4cde-a9c5-45b55ac838ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6113602391629297\n",
      "0.48616600790513836\n"
     ]
    }
   ],
   "source": [
    "bet_fav = ((df_test['fav_pred'] ==  df_test['model_pred'])&(df_test['actual_res'] == df_test['model_pred'])).sum()/(df_test['fav_pred'] ==  df_test['model_pred']).sum()\n",
    "bet_und =((df_test['fav_pred'] !=  df_test['model_pred'])&(df_test['actual_res'] == df_test['model_pred'])).sum()/(df_test['fav_pred'] !=  df_test['model_pred']).sum()\n",
    "print(bet_fav)\n",
    "print(bet_und)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe503ed0-1c32-442e-a4f3-27e4a8d99fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5649717514124294\n",
      "0.5093457943925234\n",
      "0.6280487804878049\n",
      "0.358974358974359\n"
     ]
    }
   ],
   "source": [
    "bet_away_fav = ((df_test['fav_pred'] == 0)&(df_test['model_pred'] == 0)&(df_test['actual_res'] == 0)).sum()/((df_test['fav_pred'] == 0)&(df_test['model_pred'] == 0)).sum()\n",
    "bet_away_und = ((df_test['fav_pred'] == 1)&(df_test['model_pred'] == 0)&(df_test['actual_res'] == 0)).sum()/((df_test['fav_pred'] == 1)&(df_test['model_pred'] == 0)).sum()\n",
    "bet_home_fav = ((df_test['fav_pred'] == 1)&(df_test['model_pred'] == 1)&(df_test['actual_res'] == 1)).sum()/((df_test['fav_pred'] == 1)&(df_test['model_pred'] == 1)).sum()\n",
    "bet_home_und = ((df_test['fav_pred'] == 0)&(df_test['model_pred'] == 1)&(df_test['actual_res'] == 1)).sum()/((df_test['fav_pred'] ==0)&(df_test['model_pred'] == 1)).sum()\n",
    "\n",
    "print(bet_away_fav)\n",
    "print(bet_away_und)\n",
    "print(bet_home_fav)\n",
    "print(bet_home_und)\n",
    "\n",
    "##can use these in x_17 betting model but not in the x_16 one ... except I'kk just say maybe don'tbet on away und"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eafadf6d-b9bc-4834-87bb-71f6b1850399",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = ['model_conf','home_impl_proba', 'model_conf_1', 'conf_1_sub_home_impl', 'pre_acc_sub_home_impl' \n",
    "                      ,'away_impl_proba', 'model_conf_0', 'conf_0_sub_away_impl',   'pre_acc_sub_away_impl' ,  'model_pred', 'fav_pred', 'actual_res', 'home_odds', 'away_odds',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd3705b1-d74b-4cfa-89a5-290fec534030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_name', 'actual_res', 'model_pred', 'model_conf_1',\n",
       "       'model_conf_0', 'home_odds', 'away_odds', 'home_impl_proba',\n",
       "       'away_impl_proba', 'conf_1_sub_home_impl', 'conf_0_sub_away_impl',\n",
       "       'pre_acc_sub_home_impl', 'pre_acc_sub_away_impl', 'fav_pred',\n",
       "       'model_conf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0309eb0c-869a-44aa-b63a-396b33b57db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-217.0 0.9912046044098574\n",
      "1819.0 1.5512121212121213\n",
      "4228.0 1.2146192893401015\n",
      "1495.0 1.0168519061253016\n",
      "136386.0 7325.0 1.0537078585778599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joejohns/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:3607: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_item(key, value)\n"
     ]
    }
   ],
   "source": [
    "find_pay_off(df_test17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "281f4b97-c241-4f46-98cb-51a52a3558bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1101.0 0.9576326624850887\n",
      "636.0 1.1630769230769231\n",
      "14200.0 1.6635514018691588\n",
      "201.0 1.0023223301868263\n",
      "137838.0 13936.0 1.1011041947793787\n"
     ]
    }
   ],
   "source": [
    "find_pay_off(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0edafd6e-60da-4217-bd63-cbe2c6255a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ROI of 5.3% and 10.1% respectively, avg of 7.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a0787-b12c-4a93-9957-529975bf13ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
